{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JeanMusenga/PhD-Thesis_2024_Musenga/blob/main/ArchISPE_BERTOverflow_TextCNN_Domain_Heuristics_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-RQKiona3_T"
   },
   "source": [
    "# Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68BMP4Rqog0H",
    "outputId": "8b5dd478-6b3b-40cb-b0f7-a31d7c6b064a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting swifter\n",
      "  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting textsearch>=0.0.21 (from contractions)\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from swifter) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.12/dist-packages (from swifter) (5.9.5)\n",
      "Requirement already satisfied: dask>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2025.5.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.12/dist-packages (from swifter) (4.67.1)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.3.0)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (25.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.3)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (0.12.1)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]>=2.10.0->swifter) (18.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->swifter) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\n",
      "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
      "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
      "  Downloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.12/dist-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge-score, swifter\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=7733067652f585201f15419b9a1eeee028fa91c816f28695a6cd1321383b7edd\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16505 sha256=d9349f003eed54cc0d07944d055255ff0421d78a7570fe9c2823d7cf149a4a41\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/31/ff/ff51141a088571a9f672449e5aad5ea8bb35ca5d95ba135f30\n",
      "Successfully built rouge-score swifter\n",
      "Installing collected packages: pyahocorasick, colorama, anyascii, textsearch, rouge-score, contractions, swifter\n",
      "Successfully installed anyascii-0.3.3 colorama-0.4.6 contractions-0.1.73 pyahocorasick-2.2.0 rouge-score-0.1.2 swifter-1.4.0 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions colorama rouge-score swifter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9fil57nayA9"
   },
   "source": [
    "# Import Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7HP4drAnmaZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "from rouge_score import rouge_scorer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch.optim as optim\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ipywidgets import widgets\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYPEMFx6nqpy",
    "outputId": "044c3671-8492-4182-e635-e7a6b801e009"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQe6gbIfIA-0"
   },
   "source": [
    "## Download and Load BERTOverflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "850d33cb6fff4e85acff926df3a5bbaa",
      "17e48670558a4bcc8b8e88e543700615",
      "65bf96b6e03743c2bf5cbeca503627bb",
      "00959a8db383416782df60a3b92b8767",
      "9c121e20762741c8a291acc694303e19",
      "d8991aa37965460b80ffcc56e8624a87",
      "29dcdf7abc324cd095e72a286f29eea8",
      "dfe4bb5286fe4c4a8b4a085b6c385b2a",
      "bddc680ed95144b9b18998f6149ebab5",
      "3f9652e173184f598e4f6b284f921c24",
      "a538a29f393340519f36e1f8aeee561a",
      "1215bb0d58b84832a85b2ffa03cee115",
      "6ea50c54cc354f5d9a40ffd61d1a1906",
      "014a2efed5394089aff664c401f179cd",
      "936737e5be9b4a00ba8ce0064746edbd",
      "29bf2cf6f550407ead6fc28d06454fd9",
      "8c8e0115bcdb430e8f3bbf8c6f30b3fd",
      "7c6bbb69ce8a49d4a1a233bbd7248d45",
      "6d7caf26cb2546eba71d053032f5275c",
      "4d464533425240a7bc226b2fc2418283",
      "f0680a9942ad4ff4aab6891db17d8219",
      "5b8acc1baf4946e981971057dc21cc89",
      "57689fc6db79476bacb5afb000ac1668",
      "e7237e682aa04c7c8f49357b4c9c7dc5",
      "ca08f81704e740d58c33d96945fc467a",
      "e063193dd2494a3b807e23b506c77a26",
      "774a21eb341a4b93bc871aa266dbf12d",
      "be9e47ab770446d196593626a4a6a9e4",
      "b3bbb30b1f7c4e8ab4b382f0ff588293",
      "0285414d763f4803addd0952da6925db",
      "362ab50c10564e5a849d125b9112a91a",
      "2bcc4a3b7db54f96b89ddeefc9d2634f",
      "4441d4d1e4564b55b5aeb6c0590c145e",
      "d6decd7a485a440491d3abce925b2a72",
      "1f1dafb86ba64b64855ee8786c2415f9",
      "a1f2b1e25ca94b1aa29fd4ea0cea468f",
      "023ad97e9ba44160a9697ff18deaa9ab",
      "5c63ff95f7e1496ca840182bb5957e62",
      "288edc1a97be402085dbd045e95d3dd5",
      "cb2fd13e0f244719ad0697521409d6e0",
      "00f5375fc8684ffe9eb82788195dcdc5",
      "3b4015337d7f4e6094f89f12662cda2a",
      "9ee378ec686a4dd7b6a4b272a8b3e194",
      "87201cea80db431f91a234f5d637120b",
      "6aa70269d38d48f9b397f9a20de6ab82",
      "c56906f0828442ac8cbb59fdf38c2e2a",
      "246d49f25eb0415dba513bd120c185d5",
      "5cbcd0a44bb04d24907a345d2a3c3bff",
      "69a00670bb9a430eac956dc0e2a255ef",
      "45e934b3857c48dbbc4ce7719cd4cc07",
      "b1313be74ac54a978d2f5355d04de7fc",
      "80bc6feddb2f45d1a0e524def579398b",
      "2cd4b7b4dfaf42589c096eb55469ef35",
      "40a14206ebc64f158ddc074a37912dbb",
      "717eeb71c691479e969b73c973cf11bb",
      "0bf1585bec7b43f0b621016c9a8e3fe8",
      "74ba7283744049bbbf9d3e950361d58a",
      "41b1640096d84927a4e01faa9f0984eb",
      "1db2081ee3e0441f8943a8cf4dab0314",
      "bb7cfd2c07c6481396f9c8c1e351065f",
      "ddcb91e64bd8495eba2146cc628a85e1",
      "a68bd07afe7142b0ba062f9c606cd2e6",
      "972f79ffb3944ff6a1bf41548ea6e1ed",
      "f0fe00d9c8044d0dae5cbd9eb0c530de",
      "c50ab0708af144999af6491d1365f22e",
      "77ddde1b680a49c1960ce2a8d65eee34"
     ]
    },
    "id": "x1vWCapBnsVr",
    "outputId": "69093503-9568-48c3-ec15-026c3af2031f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850d33cb6fff4e85acff926df3a5bbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1215bb0d58b84832a85b2ffa03cee115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57689fc6db79476bacb5afb000ac1668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6decd7a485a440491d3abce925b2a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa70269d38d48f9b397f9a20de6ab82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/596M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf1585bec7b43f0b621016c9a8e3fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/596M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize tokenizer and model from 'jeniya/BERTOverflow'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jeniya/BERTOverflow\")\n",
    "model = AutoModel.from_pretrained(\"jeniya/BERTOverflow\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lwe-BZOLzT2"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RB8A_8g8Ls-Z"
   },
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "dataset = pd.read_excel('367_ARPs_for_extracting_Issue_Solution_Pairs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw2VpRFy17jG"
   },
   "source": [
    "# I. Post Preprocessing Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LN2aHnzRTEON"
   },
   "outputs": [],
   "source": [
    "# Applying heuristic technique to reduce noice in the data\n",
    "def clean_dataset(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "    for a in soup.find_all('a'):\n",
    "        a.replace_with('[external-link]')\n",
    "\n",
    "    for img in soup.find_all('img'):\n",
    "        img.replace_with('[figure]')\n",
    "\n",
    "    for code in soup.find_all('code'):\n",
    "        code.replace_with('[code-snippet]')\n",
    "\n",
    "    for table in soup.find_all('table'):\n",
    "        table.replace_with('[table]')\n",
    "\n",
    "    clean_text = soup.get_text()\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# Apply the function to 'Question_body' and 'Answer_body' columns\n",
    "dataset['Question_body_cleaned'] = dataset['Question_body'].apply(clean_dataset)\n",
    "dataset['Answer_body_cleaned'] = dataset['Answer_body'].apply(clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "RLLx_pSIAoFx",
    "outputId": "716df96c-e348-4cc9-a4bc-3e61ccceed1a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dataset[['Question_body_cleaned', 'Answer_body_cleaned']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Question_body_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"which part of file structure we should do processes of fromJson and toJson? Is it business or data layer?\\nI created entity class on business layer and an entity model created on data layer which extends entity.\\nI tried to building clean architecture on my project and watching some tutorials and reading blogs but I'm confused.\\nI hope I explain my question clearly.\\nRegards\\n\",\n          \"I'm trying to properly design an application according to clean architecture, but I'm struggling to determine on which layer (data/domain) to implement certain logic. In my application, there's a feature that displays data (user contacts) which can be either set locally in settings or retrieved through an API. Which version to show the user depends on other settings and the app's usage mode, for example, the API returns data, but the user has set a preference for using local data in the app's settings. On which layer should I implement the logic for choosing the data source?\\nLet's say there is a GetUserContactsUseCase in the domain.\\nThen, as I understand it, there are several approaches:\\nApproach 1\\nUserRepository, which contains 2 sources:\\nLocalData - contains all local settings, such as contact data and priority settings.\\nRemoteData - loads and caches data from the API.\\nGetUserContactsUseCase accesses RemoteData and LocalData (which apparently need to be renamed to RemoteDataRepository and LocalDataRepository), determines the priorities, and then fetches the data from them. The downside of this solution is that it seems the Repository should be determining the data source itself.\\nApproach 2\\nUserRepository independently determines the priority. This maintains encapsulation of layers, but in this case, UserRepository contains business logic that seems like it should be in a UseCase, not a repository. It is also not possible to call a UseCase from a repository. One solution seems to be writing a separate UseCase to determine the source of UserContacts and pass its result (e.g., UserContactFetchMode) to UserRepository. This UseCase still leads back to approach 1 as it will need the same LocalData and RemoteData.\\nQuestion:\\nPlease advise on the best way to organize this.\\nI'm not sure if it's relevant to my question, but I suspect there is some confusion in the level of function distribution among the Repositories themselves, for instance, instead of having a single LocalPreferences, it might be necessary to create several instances, like LocalUserData, LocalPreferencesData, etc.\\n\",\n          \"I am building c# .NET 4.8.1 MVC web application which would allow the user to set up a potentially long running task to process possibly thousands of records. The user should be able to execute the task immediately or schedule it for a future date/time.  If they execute it immediately the web page should show a progress meter, that gets updated from the server as progress on the task occurs.  However, if they leave the page and come back (or come back after the scheduled task has started) I want to attach to the async process so the user can still get updated progress reports. The user should also have the option to pause, resume, or cancel the task through the UI as long as its running.\\nI am no expert to async architecture or programming.  Should I set up a separate WCF service to handle the backend?  How do I handle re-attaching the UI web page to the task process after its initial creation? I am storing the task details in a MS SQL Server table.  Can anyone give me some guidance on the right direction to go?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer_body_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"For the purpose of clean architecture, the fromJson and toJson methods should typically be implemented in the data layer. Let's take a look on it.\\n\\nBusiness Layer (Domain Layer):\\n\\nThe business layer contains the core logic of your application like what will happen when click on button.\\nEntities defined in the business layer should be pure representations of your domain concepts, without any knowledge of how they're persisted or serialized.\\nData Layer (Repository Layer):\\n\\nThe data is responsible for fetching, storing and managing your data.\\nIn data layer you would typically implement methods for serializing and deserializing data, such as fromJson and toJson.\\nYou can follow the architecture as:\",\n          \"Determining the source of the information is business logic, not data-access logic.  The logic does not belong in the Repository, it belongs in the UseCase.  Your repositories might return the same model, and even implement the same interfaces, but the fact that it needs to be selectable means you have business-logic involved which belongs in the UseCase.\\nBy moving the selection logic to the UseCase, you can let your repositories stay dumb, and only worry about the communication to their data-stores.\\nThis \\\"feels\\\" wrong as it seems like a separation-of-concerns issue, but it isn't.   They are different concerns BECAUSE they have the business logic to switch between them.  Put in an interface for RemoteUserContactsData and LocalUserContactsData and push the switching into the UseCase and it will become fairly obvious.\\n\",\n          \" There is no easy and reliable way to do this without splitting the task into multiple chunks. So each step of the operation must be a separate task. And all chunks together essentially represent a single distributed transaction. So this is similar to the Saga pattern, except all actions are performed by a single service.\\n[external-link]\\nSo you need to store the transaction state information in the same database. The state of the operation should be marked inside the same database transaction that performs the current stage changes. And in case the operation is canceled, you need to perform reverse operations to the stages already made.\\n The transaction state can obviously be read from the database by a separate query. Cancellation of the operation can also be marked in the database by a separate query.\\nAs a bonus, you'll be able to continue the operation after a technical glitch.\\n\\n You might want to look into the Saga design pattern, perhaps leveraging the Saga features of NServiceBus. Such a framework does much of the heavy lifting for you in terms of making sure that the process runs, even if servers temporarily go down, and you need to resume the long-running process on a different machine. It also handles synchronization in server farms.\\n\\nYou could have each Saga emit events or otherwise communicate status updates so that you can implement a progress bar.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3d93df02-b81c-4c37-bdcb-1034a81c2284\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_body_cleaned</th>\n",
       "      <th>Answer_body_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I need help with the architecture pattern I sh...</td>\n",
       "      <td>So first of all what we're talking about here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which part of file structure we should do proc...</td>\n",
       "      <td>For the purpose of clean architecture, the fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am building c# .NET 4.8.1 MVC web applicatio...</td>\n",
       "      <td>There is no easy and reliable way to do this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have a mobile application that we scale as ...</td>\n",
       "      <td>There is not a simple answer to this question....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm trying to properly design an application a...</td>\n",
       "      <td>Determining the source of the information is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d93df02-b81c-4c37-bdcb-1034a81c2284')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3d93df02-b81c-4c37-bdcb-1034a81c2284 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3d93df02-b81c-4c37-bdcb-1034a81c2284');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-ee3940b2-5476-49a8-84cf-0b34512ba813\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee3940b2-5476-49a8-84cf-0b34512ba813')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-ee3940b2-5476-49a8-84cf-0b34512ba813 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                               Question_body_cleaned  \\\n",
       "0  I need help with the architecture pattern I sh...   \n",
       "1  which part of file structure we should do proc...   \n",
       "2  I am building c# .NET 4.8.1 MVC web applicatio...   \n",
       "3  We have a mobile application that we scale as ...   \n",
       "4  I'm trying to properly design an application a...   \n",
       "\n",
       "                                 Answer_body_cleaned  \n",
       "0  So first of all what we're talking about here ...  \n",
       "1  For the purpose of clean architecture, the fro...  \n",
       "2   There is no easy and reliable way to do this ...  \n",
       "3  There is not a simple answer to this question....  \n",
       "4  Determining the source of the information is b...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[['Question_body_cleaned', 'Answer_body_cleaned']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5gvMljvnwNo"
   },
   "outputs": [],
   "source": [
    "# Performing Tokenization, Lemmatization, and Stopword Removal\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    stop_words = set(ENGLISH_STOP_WORDS)\n",
    "    processed_sentences = []\n",
    "    for sentence in sentences:\n",
    "\n",
    "        words = re.findall(r'\\b\\w+\\b', sentence.lower())\n",
    "        words = [word for word in words if word not in stop_words and word.isalpha()]\n",
    "\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        processed_sentences.append(\" \".join(lemmatized_words))\n",
    "    return sentences, processed_sentences\n",
    "\n",
    "# Preprocess question and answer bodies\n",
    "dataset['processed_question'] = dataset['Question_body_cleaned'].apply(preprocess_text)\n",
    "dataset['processed_answer'] = dataset['Answer_body_cleaned'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NSRIjNv12X-"
   },
   "source": [
    "# II. Feature Extraction Layer\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0O3oE7KZgYG"
   },
   "source": [
    "## 1. Contextual Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAmSmsJqn3AN"
   },
   "outputs": [],
   "source": [
    "# Define BERTOverflow embedding extraction\n",
    "def get_bert_embeddings(sentences):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "# Get BERT embeddings from preprocessed question and answer text\n",
    "dataset['question_embeddings'] = dataset['processed_question'].apply(lambda x: get_bert_embeddings(x[1]))\n",
    "dataset['answer_embeddings'] = dataset['processed_answer'].apply(lambda x: get_bert_embeddings(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcm54x_w2BYk"
   },
   "source": [
    "## 2. Local Feature Extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATQLP3E5n5J7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define TextCNN model with adjusted kernel sizes\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=256, filter_sizes=[2, 2, 2], num_filters=100, num_classes=256):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (filter_size, embedding_dim)) for filter_size in filter_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shape: (batch_size, seq_length, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # Apply convolution and squeeze the last dimension, resulting in a shape of (batch_size, num_filters, seq_length)\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "\n",
    "        # pply max pooling across the sequence length dimension, resulting in a shape of (batch_size, num_filters)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
    "\n",
    "        # Concatenate pooled outputs (batch_size, num_filters * len(filter_sizes))\n",
    "        x = torch.cat(x, 1)\n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define a function to extract TextCNN features\n",
    "def extract_textcnn_features(sentences, model, tokenizer, device):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        # Extract learned TextCNN features from tokenized input\n",
    "        features = model(inputs['input_ids'])\n",
    "    return features.cpu().numpy()\n",
    "\n",
    "# Initialize TextCNN model with the adjusted kernel sizes\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "\n",
    "# embedding dimension\n",
    "embedding_dim = 256\n",
    "textcnn_model = TextCNN(vocab_size, embedding_dim, filter_sizes=[2, 2, 2], num_classes=256).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGjCoLQPqOCv"
   },
   "source": [
    "## 3. Linguistic and Heuristic Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_cvHiseTYei"
   },
   "outputs": [],
   "source": [
    "# Define fucntion for question_thread to extract Linguistic and Heuristic Feature Extraction\n",
    "def q_extract_domain_specific_linguistic_patterns_heuristic_features(sentence, architectural_keywords, fiveW1H_keywords_question, linguistic_patterns):\n",
    "    features = {'contains_architecture_keywords': 0, 'contains_question_words': 0, 'contains_linguistic_patterns': 0}\n",
    "    for keyword in architectural_keywords:\n",
    "        if keyword.lower() in sentence.lower():\n",
    "            features['contains_architecture_keywords'] = 1\n",
    "            break\n",
    "    for keyword in fiveW1H_keywords_question:\n",
    "        if keyword.lower() in sentence.lower():\n",
    "            features['contains_question_words'] = 1\n",
    "            break\n",
    "    for pattern in linguistic_patterns:\n",
    "        if pattern.lower() in sentence.lower():\n",
    "            features['contains_linguistic_patterns'] = 1\n",
    "            break\n",
    "    return features\n",
    "\n",
    "# Define fucntion for answer_thread to extract Linguistic and Heuristic Feature Extraction\n",
    "def a_extract_domain_specific_linguistic_patterns_heuristic_features(sentence, architectural_keywords, linguistic_patterns):\n",
    "    features = {'contains_architecture_keywords': 0, 'contains_linguistic_patterns': 0}\n",
    "    for keyword in architectural_keywords:\n",
    "        if keyword.lower() in sentence.lower():\n",
    "            features['contains_architecture_keywords'] = 1\n",
    "            break\n",
    "    for pattern in linguistic_patterns:\n",
    "        if pattern.lower() in sentence.lower():\n",
    "            features['contains_linguistic_patterns'] = 1\n",
    "            break\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TRqUDzScwEkU"
   },
   "outputs": [],
   "source": [
    "#23 Linguistic Pattern features\n",
    "linguistic_patterns = [\n",
    "    \"I’m building\", \"How to architecture\", \"I want to design\", \"I want to build\",\"I am evaluating\",\"how to structure\",\n",
    "    \"user should\",\"I am developing\",\"I am building\", \"Advise on\",\"I recommend\",\"I cannot recommend\",\n",
    "    \"I would recommend\",\"It is recommended\",\"you don’t have to\",\"In order to\",\"critical\",\"You should\",\"A good approach\",\n",
    "    \"better than\",\"the best\",\"I would suggest\",\"I suggest\"\n",
    "]\n",
    "\n",
    "#Heuristic keywards\n",
    "fiveW1H_keywords_question = [\"What\", \"When\", \"Who\", \"Which\", \"How\", \"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGDeXQYkqQXu"
   },
   "outputs": [],
   "source": [
    "# Additional List of architectural keywords (in Linguistic Pattern) categorized for clarity\n",
    "architectural_keywords = {\n",
    "    \"Architectural Patterns and Styles\": [\n",
    "        \"Architecture pattern\", \"MVC\", \"Model View Controller\", \"Monolith\",\n",
    "        \"Microservice\", \"microservices\", \"MVP\", \"Model View Presenter\", \"MVP\",\n",
    "        \"Model View ViewModel\", \"MVVM\", \"Client-Server\", \"Client Server\", \"Client/Server\",\n",
    "        \"Layered pattern\", \"N-Tier\", \"Event Driven pattern\", \"Event Driven\",\n",
    "        \"Pipe and Filter\", \"Service Oriented Architecture\", \"SOA\", \"Broker\", \"Peer to Peer\",\n",
    "        \"Master-Slave\", \"Master and Slave\", \"Blackboard\", \"Command Query Responsibility Segregation\", \"CQRS\"\n",
    "        \"Hexagonal Architecture\", \"Publish–Subscribe\", \"Publish and Subscribe\", \"Event Sourcing\",\n",
    "        \"Reactive Architecture\", \"Database Per Service\", \"Pipe-and-Filter with Feedback Loops\",\n",
    "        \"Saga Pattern\", \"Service Mesh Architecture\", \"Strangler Fig Pattern\",\n",
    "        \"Multi-Tenant Architecture\", \"Interpreter Architecture\",\n",
    "        \"Pipeline Architecture\", \"Digital Twin Architecture\", \"User Interface\"\n",
    "        \"Monolithic\", \"Event-Driven\", \"Hybrid Architecture\", \"Clean Architecture\"\n",
    "    ],\n",
    "\n",
    "    \"Architectural Tactics\": [\n",
    "        \"Architecture tactic\", \"Design tactic\", \"Heartbeat\", \"Checkpoint\", \"Checkpointing\",\n",
    "        \"Retry Mechanism\", \"Failover Mechanism\", \"Load Balancing\", \"Caching\", \"Concurrency\",\n",
    "        \"Queue-Based Load Management\", \"Data Compression\", \"Lazy Loading\", \"Authentication\",\n",
    "        \"Authorization\", \"Data Encryption\", \"Intrusion Detection\", \"Audit Logging\",\n",
    "        \"Firewalls\", \"API Gateways\", \"Cache\", \"Caching\",\"Loose coupling\",\"Resource Pooling\",\n",
    "        \"Failover\"\n",
    "    ],\n",
    "\n",
    "    \"Software Design Principles\": [\n",
    "        \"Encapsulation\", \"Separation of Concerns\", \"Abstraction\",\n",
    "        \"Component-Based Design\", \"Refactoring\", \"Plug-in Architecture\"\n",
    "    ],\n",
    "\n",
    "    \"Scalability and Performance Optimization\": [\n",
    "        \"Horizontal Scaling\", \"Scale-Out\", \"Vertical Scaling\", \"Scale-Up\",\n",
    "        \"Sharding\", \"Database Replication\", \"Progressive Disclosure\",\"Server Replication\",\n",
    "        \"Undo Mechanism\", \"Redo Mechanism\", \"Event-Bus Pattern\"\n",
    "    ],\n",
    "\n",
    "    \"Reliability and Fault Tolerance\": [\n",
    "        \"Consistent UI Design\", \"Removal from service\", \"Exception Prevention\",\n",
    "        \"Introduce Concurrency\", \"Maintain Multiple Copies of Data\", \"Bound Queue Sizes\",\n",
    "        \"Schedule Resources\", \"Manage Resources\", \"Manage Sampling Rate\", \"Limit Event Response\",\n",
    "        \"Prioritize Events\", \"Bound Execution Times\", \"Increase Resource Efficiency\"\n",
    "    ],\n",
    "\n",
    "    \"Networking and Communication\": [\n",
    "        \"REST\", \"SOAP\", \"WCF\", \"Ping/Echo\", \"Ping and Echo\",\"Shadow\", \"Active Redundancy\", \"Monitor\",\n",
    "        \"Timestamp\", \"Sanity Checking\", \"Voting\", \"Condition Monitoring\"\n",
    "    ],\n",
    "\n",
    "\n",
    "    \"Security Strategies\": [\n",
    "        \"Increase Resources\", \"Maintain Multiple Copies of Computations\",\n",
    "        \"Detect Intrusion\", \"Detect Service Denial\", \"Verify Message Integrity\",\n",
    "        \"Detect Message Delay\", \"Identify Actors\", \"Limit Access\",\n",
    "        \"Limit Exposure\", \"Encrypt Data\"\n",
    "    ],\n",
    "\n",
    "\n",
    "    \"Modularity and Maintainability\": [\n",
    "        \"Tailor Interface\", \"Reduce Size of a Module\", \"Split Module\",\n",
    "        \"Increase Cohesion\", \"Increase Semantic Coherence\", \"Reduce Coupling\",\n",
    "        \"Encapsulate\", \"Use an Intermediary\", \"Restrict Dependency\", \"Refactor\",\n",
    "        \"Abstract Common Services\", \"Reduce Overhead\", \"Limit Nondeterminism\",\n",
    "        \"Limit Structural Complexity\", \"Limit Complexity\"\n",
    "    ],\n",
    "\n",
    "    \"Architecture Design Decision\": [\n",
    "        \"Architecture decision\", \"Trade-offs\", \"Requirements\", \"MongoDB\", \"Redis\"\n",
    "        , \"Redis\" , \"MySQL\" , \"PostgreSQL\" , \"SQL Server\", \"Amazon DynamoDB\", \"TimescaleDB\", \"InfluxDB\"\n",
    "    ],\n",
    "\n",
    "    \"Design Context\": [\n",
    "        \"Embedded System\", \"Mobile Application\", \"Web Application\",\n",
    "        \"Information System\", \"Game application\", \"E-commerce\", \"Distributed System\",\n",
    "        \"Banking System\", \"Android\", \"iOS\", \"Window\",\n",
    "    ],\n",
    "\n",
    "    \"Maintainability\": [\n",
    "        \"Maintainability\", \"Update\", \"Modify\", \"Modular\", \"Decentralized\",\n",
    "        \"Encapsulation\", \"Dependency\", \"Readability\", \"Interdependent\",\n",
    "        \"Understandability\", \"Modifiability\", \"Modularity\", \"Maintain\",\n",
    "        \"Analyzability\", \"Changeability\", \"Testability\"\n",
    "    ],\n",
    "\n",
    "    \"Performance (Efficiency)\": [\n",
    "        \"Performance\", \"Processing time\", \"Response time\", \"Resource Consumption\",\n",
    "        \"Throughput\", \"Efficiency\", \"Operation\", \"Achievement\", \"Interaction\",\n",
    "        \"Accomplishment\", \"Parallelism\"\n",
    "    ],\n",
    "\n",
    "    \"Usability\": [\n",
    "        \"Usability\", \"Flexibility\", \"Interface\", \"User-friendly\",\n",
    "        \"Configurable\", \"Serviceability\", \"Accessibility\", \"Customizable\"\n",
    "    ]\n",
    "}\n",
    "# this list can be extanded during the future research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxQ4aXAT2L4E"
   },
   "source": [
    "# III. Similarity and Relevancy Assessment Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aL5pEQ1BKrb"
   },
   "source": [
    "## Function for identifying relevant and important issue sentences within a question body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Qf47FgT5_xz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def question_score_sentences_with_combined_features(question_sentences, question_embeddings,\n",
    "                                                    textcnn_features, weight_bert=0.4, weight_textcnn=0.2, weight_heuristic=0.1,\n",
    "                                                    architectural_keywords=[], fiveW1H_keywords_question=[], linguistic_patterns=[]):\n",
    "\n",
    "    q_sentence_scores = []\n",
    "\n",
    "    full_question_embedding = np.mean(question_embeddings, axis=0)\n",
    "\n",
    "    for i, (q_sentence, tcnn_features) in enumerate(zip(question_sentences, textcnn_features)):\n",
    "\n",
    "        # BERT-based Score using cosine similarity\n",
    "        if i < len(question_embeddings):\n",
    "            bert_score = cosine_similarity(\n",
    "                [question_embeddings[i]], [full_question_embedding])[0][0]\n",
    "        else:\n",
    "            bert_score = 0\n",
    "\n",
    "        # TextCNN score\n",
    "        textcnn_score = weight_textcnn * np.mean(tcnn_features) if isinstance(tcnn_features, np.ndarray) and tcnn_features.size > 0 else 0\n",
    "\n",
    "        # Heuristic Score (e.g., sentence length)\n",
    "        sentence_length = len(q_sentence.split())\n",
    "        max_length = max(len(s.split()) for s in question_sentences)\n",
    "        heuristic_score = sentence_length / max_length if max_length > 0 else 0\n",
    "\n",
    "\n",
    "        # Extract domain-specific, heuristic, linguistic features\n",
    "        q_features = q_extract_domain_specific_linguistic_patterns_heuristic_features(\n",
    "            q_sentence, architectural_keywords, fiveW1H_keywords_question, linguistic_patterns)\n",
    "\n",
    "\n",
    "        # Combine all features\n",
    "        q_combined_score = (weight_heuristic * heuristic_score) + \\\n",
    "                           (weight_bert * bert_score) + \\\n",
    "                           (weight_textcnn * textcnn_score) + \\\n",
    "                           (q_features['contains_architecture_keywords'] * 0.1) + \\\n",
    "                           (q_features['contains_question_words'] * 0.1) + \\\n",
    "                           (q_features['contains_linguistic_patterns'] * 0.1)\n",
    "\n",
    "        q_sentence_scores.append(q_combined_score)\n",
    "\n",
    "    return q_sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opzWuYZzjfj6"
   },
   "outputs": [],
   "source": [
    "dataset['question_scores'] = dataset.apply(lambda x: question_score_sentences_with_combined_features(\n",
    "    x['processed_question'][0],\n",
    "    x['question_embeddings'],\n",
    "    extract_textcnn_features(x['processed_question'][0], textcnn_model, tokenizer, device),\n",
    "    architectural_keywords=architectural_keywords,\n",
    "    fiveW1H_keywords_question=fiveW1H_keywords_question,\n",
    "    linguistic_patterns=linguistic_patterns\n",
    "), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ve4uRAo134V"
   },
   "source": [
    "## Function for identifying relevant and important solution sentences within a answer body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjUZX8NsYdmL"
   },
   "outputs": [],
   "source": [
    "def answer_score_sentences_with_combined_features(question_sentences, answer_sentences, question_embeddings, answer_embeddings,\n",
    "                                                  textcnn_features, weight_bert=0.5, weight_textcnn=0.2, weight_heuristic=0.1,\n",
    "                                                  architectural_keywords=[], fiveW1H_keywords_question=[], linguistic_patterns=[]):\n",
    "    a_sentence_scores = []\n",
    "\n",
    "    for a_sentence, a_embedding, tcnn_features in zip(answer_sentences, answer_embeddings, textcnn_features):\n",
    "        a_embedding = a_embedding.reshape(1, -1)\n",
    "        similarities = [cosine_similarity(a_embedding, q_embedding.reshape(1, -1))[0][0] for q_embedding in question_embeddings]\n",
    "        q_a_bert_score = np.mean(similarities)\n",
    "\n",
    "        if isinstance(tcnn_features, np.ndarray) and tcnn_features.size > 0:\n",
    "            textcnn_score = weight_textcnn * np.mean(tcnn_features)\n",
    "        else:\n",
    "            textcnn_score = 0\n",
    "\n",
    "        # Heuristic Score (e.g., sentence length)\n",
    "        a_sentence_length = len(a_sentence.split())\n",
    "        a_heuristic_score = a_sentence_length / max(len(s.split()) for s in question_sentences)\n",
    "\n",
    "        # Extract domain-specific, heuristic, Linguistic feature Extraction\n",
    "        a_donain_linguistic_patterns_heuristic_features = q_extract_domain_specific_linguistic_patterns_heuristic_features(\n",
    "            a_sentence, architectural_keywords, fiveW1H_keywords_question, linguistic_patterns)\n",
    "\n",
    "        # Combine features with respective weights\n",
    "        a_combined_score = (weight_bert * q_a_bert_score) + (weight_heuristic * a_heuristic_score) + \\\n",
    "                           (weight_textcnn * textcnn_score) + \\\n",
    "                           (a_donain_linguistic_patterns_heuristic_features['contains_architecture_keywords'] * 0.1) + \\\n",
    "                           (a_donain_linguistic_patterns_heuristic_features['contains_linguistic_patterns'] * 0.1)\n",
    "\n",
    "        a_sentence_scores.append(a_combined_score)\n",
    "\n",
    "    return a_sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_Gb6x34YRft"
   },
   "outputs": [],
   "source": [
    "dataset['answer_scores'] = dataset.apply(lambda x: answer_score_sentences_with_combined_features(\n",
    "    x['processed_question'][0],\n",
    "    x['processed_answer'][0],\n",
    "    x['question_embeddings'],\n",
    "    x['answer_embeddings'],\n",
    "\n",
    "    extract_textcnn_features(x['processed_answer'][0], textcnn_model, tokenizer, device),\n",
    "    architectural_keywords=architectural_keywords,\n",
    "    linguistic_patterns=linguistic_patterns),\n",
    "axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T93MzysU2QOO"
   },
   "source": [
    "# V. Output Layer: Sentence Importance Ranking and Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMaK1egEHtjJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#  Extracts the top-k most important sentences based on model scores mwhile preserving their original order in the text.\n",
    "def issue_solution_extraction(original_sentences, scores, num_sentences=6):\n",
    "\n",
    "    num_sentences = min(num_sentences, len(original_sentences))\n",
    "\n",
    "    # Step 1: Get indices of top-k sentences by descending score\n",
    "    ranked_sentence_indices = np.argsort(scores)[::-1][:num_sentences]\n",
    "\n",
    "    # Step 2: Sort those indices by their original order\n",
    "    ordered_indices = sorted(ranked_sentence_indices)\n",
    "\n",
    "    # Step 3: Extract and concatenate sentences in natural order\n",
    "    issue_solution = [original_sentences[idx] for idx in ordered_indices]\n",
    "    return \" \".join(issue_solution)\n",
    "\n",
    "# Apply the extraction function to both question and answer parts\n",
    "dataset['Issue_Extracted'] = dataset.apply(\n",
    "    lambda x: issue_solution_extraction(\n",
    "        x['processed_question'][0],\n",
    "        x['question_scores']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "dataset['Solution_Extracted'] = dataset.apply(\n",
    "    lambda x: issue_solution_extraction(\n",
    "        x['processed_answer'][0],\n",
    "        x['answer_scores']\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCymFx-6Gc_f",
    "outputId": "dbf9f013-7ee2-42f3-f723-418b318bb9fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset with the extracted issues and solutions\n",
    "try:\n",
    "    dataset.to_excel('/content/fileName.xlsx', index=False, engine='openpyxl')\n",
    "    print(\"File saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "bdaD4cWhZOoY",
    "outputId": "037f948c-81c7-4dac-8e3f-9487648d9d28"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"issue_solutions\",\n  \"rows\": 367,\n  \"fields\": [\n    {\n      \"column\": \"Question_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 366,\n        \"samples\": [\n          \"Architecture of VS Code\",\n          \"Integrating Spring State Machine in a Hexagonal Architecture\",\n          \"General architecture for React calling AWS and SQS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Issue_Extracted\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 366,\n        \"samples\": [\n          \"Are there articles or presentations about building VS Code - architecture, approach for plug-ins, any abilities to communicate with OS specific stuff etc? First idea is to move stuff to .NET Core, although I am not sure how difficult that is for apps that are using Windows specific resources. All I know is that Electron is used for UI, you can write plug-in for almost any part and it is open-source (or at least Codium is). Therefore, I would like to learn more about architecture, what other languages are used for components and why, what problems were faced etc. But except for some basic info, I end up finding how to create solutions using VS Code. So do you know some good links, perhaps not specifically about VS Code but similar architectural solutions?\",\n          \"Questions:\\n1. Business Logic Implementation in Hexagonal Architecture:\\nIn a hexagonal architecture, where is the best place to implement the logic for state transitions, especially considering the need for sending/waiting for messages and making REST calls within certain states? State Machine and Service Layer Interaction:\\nHow should I structure the interaction between the service layer and state machines in this context? I am looking for best practices that fit within the hexagonal architecture paradigm and ensure maintainability. Configurations for State-Dependent REST Calls:\\nCould you provide examples or best practices for configuring state machines in Spring Boot where states involve making REST calls? Handling Message Responses:\\nHow can I effectively manage the scenarios where the state machine sends a message and needs to wait for a response before moving to the next state? What I've Tried and What I'm Expecting:\\nSo far, I have set up the basic structure of the application following hexagonal architecture principles, separating the core logic from external dependencies.\",\n          \"While waiting for a response, the react app will show status updates, meaning the different stages of the operation taking place on the server. So that's how I'd build it: React calls API gateway, which in turn calls a Lamba function, which then calls SQS and sends a message on some queue. Is it a 2-way queue, is Lambda keep polling it until there's an answer and then return it to the client, or would there be two Lambdas? Would there be some sort of Id when sending, and the third party returns a queue message when it's done with that Id that we can match them, or\\\"\\u00a6? What would trigger that 2nd Lamba (if we're doing two lambdas) a message arriving in queue would be the trigger, or would it keep polling, or\\\"\\u00a6? Would it be all about querying some API over HTTP (with Axios or Fetch API or whatever) or would it be some NPM package that queries a queue, in which case I might not even need Lambda checking for a return message, like Amplify from aws-amplify..?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solution_Extracted\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 366,\n        \"samples\": [\n          \"If you want to build a generic cross platform application, perhaps you should start look into Electron (or NW.js) rather than VSCode. Everything is JavaScript (or TypeScript), Node.JS processes and an embedded Chromium browser for rendering \\\"web pages\\\" to construct the application. The real UI part is actually whatever you want, like React, Angular or some plain vanilla HTML+CSS+JavaScript. Essentially - you are shipping a browser with a pre-loaded web page and a bundled Node.JS backend as your application. The major part of your application architecture will be the same as for any browser based application using HTML5. A walk through of the internal architecture of Electron: [external-link]\\nAs you likely already have a ton of C# code and libraries - as well as C# coders - that you may want to reuse there is also a .NET version of Electron [external-link] .\",\n          \"1, 2: It is not clear how u use your state machines or why you are using them. But if you are using them as orchestrators, that have access to all different layers (u mentioned business logic, messages + rest calls etc), then this is obviously violating the architecture. If not, then it should be straight-forward in which layer to put it. If you dont do async calls, then the execution wont progress until you get the response. 4: For state transitions i ve only seen actions to be used. Listeners can be also used for some other actions, like for [external-link]\",\n          \"In order to send a response you need to keep the request that reached lambda \\\"open\\\" (=lambda is running, i.e. Which I cannot recommend. If it waits until something is resolved, you will be paying for it as long as it open. (you have to provide docker image, not just code, but then it is basically also serverless, you dont have to care about anything). With container you can also use Websockets, which essentially do what you want (you dont have to do long polling/status polling, you can update client proactively from backend through the websocket). The most simple solution using serverless would be probably with 3+ lambdas:\\n\\nStart the flow (=sending something to the Queue)\\n(1 or more lambdas) Process whatever you need, I dont know triggers if 3rd party sends you webhook or you are connected to that 3rd party queue and they let you know something is finished.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "issue_solutions"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-0ab57f39-9ae3-4b54-858d-3200fabb1fe3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_title</th>\n",
       "      <th>Issue_Extracted</th>\n",
       "      <th>Solution_Extracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Separation of Students and Users in NestJS Mic...</td>\n",
       "      <td>I need help with the architecture pattern I sh...</td>\n",
       "      <td>Right now what I am doing is, in createStudent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flutter Clean Architecture</td>\n",
       "      <td>which part of file structure we should do proc...</td>\n",
       "      <td>For the purpose of clean architecture, the fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Correct .NET Architecture for long running asy...</td>\n",
       "      <td>I am building c# .NET 4.8.1 MVC web applicatio...</td>\n",
       "      <td>There is no easy and reliable way to do this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecture for white-label mobile apps with ...</td>\n",
       "      <td>We have a mobile application that we scale as ...</td>\n",
       "      <td>Think of how Tailwind or Nativewind works, tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Implementing Data Source Selection Logic in Cl...</td>\n",
       "      <td>I'm trying to properly design an application a...</td>\n",
       "      <td>Determining the source of the information is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ab57f39-9ae3-4b54-858d-3200fabb1fe3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0ab57f39-9ae3-4b54-858d-3200fabb1fe3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0ab57f39-9ae3-4b54-858d-3200fabb1fe3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-7c5b995d-24fe-41b9-9382-88de8533a10a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c5b995d-24fe-41b9-9382-88de8533a10a')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-7c5b995d-24fe-41b9-9382-88de8533a10a button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                      Question_title  \\\n",
       "0  Separation of Students and Users in NestJS Mic...   \n",
       "1                         Flutter Clean Architecture   \n",
       "2  Correct .NET Architecture for long running asy...   \n",
       "3  Architecture for white-label mobile apps with ...   \n",
       "4  Implementing Data Source Selection Logic in Cl...   \n",
       "\n",
       "                                     Issue_Extracted  \\\n",
       "0  I need help with the architecture pattern I sh...   \n",
       "1  which part of file structure we should do proc...   \n",
       "2  I am building c# .NET 4.8.1 MVC web applicatio...   \n",
       "3  We have a mobile application that we scale as ...   \n",
       "4  I'm trying to properly design an application a...   \n",
       "\n",
       "                                  Solution_Extracted  \n",
       "0  Right now what I am doing is, in createStudent...  \n",
       "1  For the purpose of clean architecture, the fro...  \n",
       "2   There is no easy and reliable way to do this ...  \n",
       "3  Think of how Tailwind or Nativewind works, tak...  \n",
       "4  Determining the source of the information is b...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the extracted issues and solutions\n",
    "issue_solutions = dataset[['Question_title', 'Issue_Extracted', 'Solution_Extracted']]\n",
    "issue_solutions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve1IN8JEQ08j"
   },
   "source": [
    "# Evaluate the extracted issue-solution pairs using Precsion, Recall, and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkuG-3RfS7DF",
    "outputId": "9bb11ce4-b0c8-4161-b452-97750fc5a3c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Precision, Recall, F1 Scores for \u001b[31mQuestions\u001b[0m:\n",
      "Question_precision    0.883893\n",
      "Question_recall       0.884953\n",
      "Question_f1           0.883493\n",
      "dtype: float64\n",
      "\n",
      "Mean Precision, Recall, F1 Scores for \u001b[31mAnswers\u001b[0m:\n",
      "Answer_precision    0.897541\n",
      "Answer_recall       0.891663\n",
      "Answer_f1           0.893854\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_extracted_Issue_solutions_at_sentence_level(df, ref_col, gen_col):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        ref_issue_solution = row[ref_col]\n",
    "        gen_issue_solution = row[gen_col]\n",
    "\n",
    "        if pd.isna(ref_issue_solution) or pd.isna(gen_issue_solution):\n",
    "            continue\n",
    "\n",
    "        ref_sentences = nltk.sent_tokenize(ref_issue_solution)\n",
    "        gen_sentences = nltk.sent_tokenize(gen_issue_solution)\n",
    "\n",
    "        ref_sentences_set = set(ref_sentences)\n",
    "        gen_sentences_set = set(gen_sentences)\n",
    "\n",
    "        precision = len(ref_sentences_set & gen_sentences_set) / len(gen_sentences_set) if gen_sentences_set else 0\n",
    "        recall = len(ref_sentences_set & gen_sentences_set) / len(ref_sentences_set) if ref_sentences_set else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'precision': precision_list,\n",
    "        'recall': recall_list,\n",
    "        'f1': f1_list\n",
    "    })\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "# Load the dataFrame containing both the extracted issue–solution pairs and the ground-truth data\n",
    "df = pd.read_excel('ArchISPE_results.xlsx')\n",
    "\n",
    "question_metrics_df = evaluate_extracted_Issue_solutions_at_sentence_level(df, 'Ground_truth_Issue_Labeled', 'Issue_Extracted')\n",
    "answer_metrics_df = evaluate_extracted_Issue_solutions_at_sentence_level(df, 'Ground_truth_Solution_Labeled', 'Solution_Extracted')\n",
    "\n",
    "# Separate evaluation for question and answer summaries, retaining individual columns for comparison\n",
    "question_metrics_df.columns = [f'Question_{col}' for col in question_metrics_df.columns]\n",
    "answer_metrics_df.columns = [f'Answer_{col}' for col in answer_metrics_df.columns]\n",
    "\n",
    "# Combine question and answer results into a single DataFrame\n",
    "combined_metrics_df = pd.concat([question_metrics_df, answer_metrics_df], axis=1)\n",
    "\n",
    "# Compute Precision, Recall, F1 scores\n",
    "mean_question_metrics = question_metrics_df.mean()\n",
    "mean_answer_metrics = answer_metrics_df.mean()\n",
    "\n",
    "print(\"\\nMean Precision, Recall, F1 Scores for \\033[31mQuestions\\033[0m:\")\n",
    "print(mean_question_metrics)\n",
    "\n",
    "print(\"\\nMean Precision, Recall, F1 Scores for \\033[31mAnswers\\033[0m:\")\n",
    "print(mean_answer_metrics)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
