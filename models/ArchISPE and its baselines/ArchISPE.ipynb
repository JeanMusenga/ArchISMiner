{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeanMusenga/PhD-Thesis_2024_Musenga/blob/main/ArchISPE_BERTOverflow_TextCNN_Domain_Heuristics_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install necessary libraries"
      ],
      "metadata": {
        "id": "Q-RQKiona3_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68BMP4Rqog0H",
        "outputId": "cd8e737f-652c-40fb-f9c9-7ce28c1be874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.12/dist-packages (0.1.73)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: swifter in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.12/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from swifter) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.12/dist-packages (from swifter) (5.9.5)\n",
            "Requirement already satisfied: dask>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2025.5.0)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.12/dist-packages (from swifter) (4.67.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.3.0)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (25.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.3)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (0.12.1)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.12/dist-packages (from dask[dataframe]>=2.10.0->swifter) (18.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->swifter) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.12/dist-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.12/dist-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions colorama rouge-score swifter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Important Libraries"
      ],
      "metadata": {
        "id": "W9fil57nayA9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7HP4drAnmaZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "from rouge_score import rouge_scorer\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch.optim as optim\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from ipywidgets import widgets\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYPEMFx6nqpy",
        "outputId": "eecc4e70-37a4-42c0-b03d-f782c035fe6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Downloading necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Load BERTOverflow Model"
      ],
      "metadata": {
        "id": "RQe6gbIfIA-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1vWCapBnsVr"
      },
      "outputs": [],
      "source": [
        "# Initialize tokenizer and model from 'jeniya/BERTOverflow'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"jeniya/BERTOverflow\")\n",
        "model = AutoModel.from_pretrained(\"jeniya/BERTOverflow\").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "_lwe-BZOLzT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load your dataset from here\n",
        "dataset = pd.read_excel('fileName.xlsx')"
      ],
      "metadata": {
        "id": "RB8A_8g8Ls-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw2VpRFy17jG"
      },
      "source": [
        "# I. Post Preprocessing Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN2aHnzRTEON"
      },
      "outputs": [],
      "source": [
        "# Applying heuristic technique to reduce noice in the data\n",
        "def clean_dataset(text):\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "\n",
        "    for a in soup.find_all('a'):\n",
        "        a.replace_with('[external-link]')\n",
        "\n",
        "    for img in soup.find_all('img'):\n",
        "        img.replace_with('[figure]')\n",
        "\n",
        "    for code in soup.find_all('code'):\n",
        "        code.replace_with('[code-snippet]')\n",
        "\n",
        "    for table in soup.find_all('table'):\n",
        "        table.replace_with('[table]')\n",
        "\n",
        "    clean_text = soup.get_text()\n",
        "\n",
        "    return clean_text\n",
        "\n",
        "# Apply the function to 'Question_body' and 'Answer_body' columns\n",
        "dataset['Question_body_cleaned'] = dataset['Question_body'].apply(clean_dataset)\n",
        "dataset['Answer_body_cleaned'] = dataset['Answer_body'].apply(clean_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RLLx_pSIAoFx",
        "outputId": "5109f49a-280b-4bfe-c8f1-d9ccd74bcb70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Question_body_cleaned  \\\n",
              "0  I need help with the architecture pattern I sh...   \n",
              "1  which part of file structure we should do proc...   \n",
              "2  I am building c# .NET 4.8.1 MVC web applicatio...   \n",
              "3  We have a mobile application that we scale as ...   \n",
              "4  I'm trying to properly design an application a...   \n",
              "\n",
              "                                 Answer_body_cleaned  \n",
              "0  So first of all what we're talking about here ...  \n",
              "1  For the purpose of clean architecture, the fro...  \n",
              "2  There is no easy and reliable way to do this w...  \n",
              "3  There is not a simple answer to this question....  \n",
              "4  Determining the source of the information is b...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3eb532dc-d64a-4d69-b022-41b7c50dff1e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question_body_cleaned</th>\n",
              "      <th>Answer_body_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I need help with the architecture pattern I sh...</td>\n",
              "      <td>So first of all what we're talking about here ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>which part of file structure we should do proc...</td>\n",
              "      <td>For the purpose of clean architecture, the fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am building c# .NET 4.8.1 MVC web applicatio...</td>\n",
              "      <td>There is no easy and reliable way to do this w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We have a mobile application that we scale as ...</td>\n",
              "      <td>There is not a simple answer to this question....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I'm trying to properly design an application a...</td>\n",
              "      <td>Determining the source of the information is b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3eb532dc-d64a-4d69-b022-41b7c50dff1e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3eb532dc-d64a-4d69-b022-41b7c50dff1e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3eb532dc-d64a-4d69-b022-41b7c50dff1e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8a4c6e3c-34f7-46de-a370-bdc2db666720\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a4c6e3c-34f7-46de-a370-bdc2db666720')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8a4c6e3c-34f7-46de-a370-bdc2db666720 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset[['Question_body_cleaned', 'Answer_body_cleaned']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Question_body_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"which part of file structure we should do processes of fromJson and toJson?\\nIs it business or data layer?\\nI created entity class on business layer and an entity model created on data layer which extends entity.\\nI tried to building clean architecture on my project and watching some tutorials and reading blogs but I'm confused.\\nI hope I explain my question clearly.\\n\",\n          \"I'm trying to properly design an application according to clean architecture, but I'm struggling to determine on which layer (data/domain) to implement certain logic. \\nIn my application, there's a feature that displays data (user contacts) which can be either set locally in settings or retrieved through an API.\\n Which version to show the user depends on other settings and the app's usage mode, for example, the API returns data, but the user has set a preference for using local data in the app's settings.\\n On which layer should I implement the logic for choosing the data source?\\nLet's say there is a GetUserContactsUseCase in the domain.\\nApproach 1: UserRepository, which contains 2 sources,  LocalData - contains all local settings, such as contact data and priority settings.\\nRemoteData - loads and caches data from the API.\\nGetUserContactsUseCase accesses RemoteData and LocalData (which apparently need to be renamed to RemoteDataRepository and LocalDataRepository), determines the priorities, and then fetches the data from them. \\nThe downside of this solution is that it seems the Repository should be determining the data source itself.\\nApproach 2: UserRepository independently determines the priority. This maintains encapsulation of layers, but in this case, UserRepository contains business logic that seems like it should be in a UseCase, not a repository.\\n It is also not possible to call a UseCase from a repository. \\nOne solution seems to be writing a separate UseCase to determine the source of UserContacts and pass its result (e.g., UserContactFetchMode) to UserRepository. \\nThis UseCase still leads back to approach 1 as it will need the same LocalData and RemoteData.\\nQuestion: Please advise on the best way to organize this.\\nI'm not sure if it's relevant to my question, but I suspect there is some confusion in the level of function distribution among the Repositories themselves, for instance, instead of having a single LocalPreferences, it might be necessary to create several instances, like LocalUserData, LocalPreferencesData, etc.\\n\",\n          \"I am building c# .NET 4.8.1 MVC web application which would allow the user to set up a potentially long running task to process possibly thousands of records. \\nThe user should be able to execute the task immediately or schedule it for a future date/time. \\n If they execute it immediately the web page should show a progress meter, that gets updated from the server as progress on the task occurs.  \\nHowever, if they leave the page and come back (or come back after the scheduled task has started) I want to attach to the async process so the user can still get updated progress reports. \\nThe user should also have the option to pause, resume, or cancel the task through the UI as long as its running.\\nI am no expert to async architecture or programming.\\n Should I set up a separate WCF service to handle the backend? \\n How do I handle re-attaching the UI web page to the task process after its initial creation? I am storing the task details in a MS SQL Server table. \\n Can anyone give me some guidance on the right direction to go?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer_body_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"For the purpose of clean architecture, the fromJson and toJson methods should typically be implemented in the data layer. Let's take a look on it.\\nBusiness Layer (Domain Layer),  the business layer contains the core logic of your application like what will happen when click on button.\\nEntities defined in the business layer should be pure representations of your domain concepts, without any knowledge of how they're persisted or serialized.\\nData Layer (Repository Layer),  the data is responsible for fetching, storing and managing your data.\\nIn data layer you would typically implement methods for serializing and deserializing data, such as fromJson and toJson.\\nYou can follow the architecture as,  [code].\",\n          \"Determining the source of the information is business logic, not data-access logic. \\nThe logic does not belong in the Repository, it belongs in the UseCase. \\nYour repositories might return the same model, and even implement the same interfaces, but the fact that it needs to be selectable means you have business-logic involved which belongs in the UseCase.\\nBy moving the selection logic to the UseCase, you can let your repositories stay dumb, and only worry about the communication to their data-stores.\\nThis \\\"feels\\\" wrong as it seems like a separation-of-concerns issue, but it isn't.  \\nThey are different concerns BECAUSE they have the business logic to switch between them.  \\nPut in an interface for RemoteUserContactsData and LocalUserContactsData and push the switching into the UseCase and it will become fairly obvious.\\n\",\n          \"There is no easy and reliable way to do this without splitting the task into multiple chunks. So each step of the operation must be a separate task. And all chunks together essentially represent a single distributed transaction. So this is similar to the Saga pattern, except all actions are performed by a single service, [external-link]. \\nSo you need to store the transaction state information in the same database. The state of the operation should be marked inside the same database transaction that performs the current stage changes. And in case the operation is canceled, you need to perform reverse operations to the stages already made.\\n The transaction state can obviously be read from the database by a separate query. Cancellation of the operation can also be marked in the database by a separate query.\\nAs a bonus, you'll be able to continue the operation after a technical glitch.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "dataset[['Question_body_cleaned', 'Answer_body_cleaned']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5gvMljvnwNo"
      },
      "outputs": [],
      "source": [
        "# Tokenization, Lemmatization, and Stopword Removal\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def preprocess_text(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    stop_words = set(ENGLISH_STOP_WORDS)\n",
        "    processed_sentences = []\n",
        "    for sentence in sentences:\n",
        "\n",
        "        words = re.findall(r'\\b\\w+\\b', sentence.lower())\n",
        "        words = [word for word in words if word not in stop_words and word.isalpha()]\n",
        "\n",
        "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "        processed_sentences.append(\" \".join(lemmatized_words))\n",
        "    return sentences, processed_sentences\n",
        "\n",
        "# Preprocess question and answer bodies\n",
        "dataset['processed_question'] = dataset['Question_body_cleaned'].apply(preprocess_text)\n",
        "dataset['processed_answer'] = dataset['Answer_body_cleaned'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NSRIjNv12X-"
      },
      "source": [
        "# II. Feature Extraction Layer\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0O3oE7KZgYG"
      },
      "source": [
        "## 1. Contextual Feature Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAmSmsJqn3AN"
      },
      "outputs": [],
      "source": [
        "# Define BERTOverflow embedding extraction\n",
        "def get_bert_embeddings(sentences):\n",
        "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Extract embeddings from the [CLS] token for each sentence and get mean of token embeddings for each sentence\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings.cpu().numpy()\n",
        "\n",
        "# Get BERT embeddings from preprocessed question and answer text\n",
        "dataset['question_embeddings'] = dataset['processed_question'].apply(lambda x: get_bert_embeddings(x[1]))\n",
        "dataset['answer_embeddings'] = dataset['processed_answer'].apply(lambda x: get_bert_embeddings(x[1]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape of embeddings in the first 3 rows\n",
        "for i in range(3):\n",
        "    emb = dataset['question_embeddings'].iloc[i]\n",
        "    print(f\"Row {i} - question embedding shape: {emb.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Elv55IclUrzr",
        "outputId": "876faeb6-be6b-4843-b74a-0200bf7b4b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 0 - question embedding shape: (15, 768)\n",
            "Row 1 - question embedding shape: (5, 768)\n",
            "Row 2 - question embedding shape: (10, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all sentence embeddings are the same size (should be 768 for BERT)\n",
        "vector_sizes = dataset['question_embeddings'].apply(lambda x: [vec.shape[0] for vec in x])\n",
        "print(vector_sizes.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YIEKJ6AVWHu",
        "outputId": "9f3c3a35-ea56-4911-e4ce-9131574ab51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768], [768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768], [768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768], [768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768], [768], [768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768], [768, 768, 768, 768, 768, 768, 768, 768, 768, 768, 768]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcm54x_w2BYk"
      },
      "source": [
        "## 2. Local Feature Extractor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATQLP3E5n5J7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define TextCNN model with adjusted kernel sizes\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=256, filter_sizes=[2, 2, 2], num_filters=100, num_classes=256):\n",
        "        super(TextCNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(1, num_filters, (filter_size, embedding_dim)) for filter_size in filter_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * num_filters, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shape: (batch_size, seq_length, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # Apply convolution and squeeze the last dimension, resulting in a shape of (batch_size, num_filters, seq_length)\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
        "\n",
        "        # pply max pooling across the sequence length dimension, resulting in a shape of (batch_size, num_filters)\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
        "\n",
        "        # Concatenate pooled outputs (batch_size, num_filters * len(filter_sizes))\n",
        "        x = torch.cat(x, 1)\n",
        "        # Fully connected layer\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define a function to extract TextCNN features\n",
        "def extract_textcnn_features(sentences, model, tokenizer, device):\n",
        "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        # Extract learned TextCNN features from tokenized input\n",
        "        features = model(inputs['input_ids'])\n",
        "    return features.cpu().numpy()\n",
        "\n",
        "# Initialize TextCNN model with the adjusted kernel sizes\n",
        "vocab_size = len(tokenizer.vocab)\n",
        "\n",
        "# embedding dimension\n",
        "embedding_dim = 256\n",
        "textcnn_model = TextCNN(vocab_size, embedding_dim, filter_sizes=[2, 2, 2], num_classes=256).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGjCoLQPqOCv"
      },
      "source": [
        "## 3. Linguistic Pattern Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_cvHiseTYei"
      },
      "outputs": [],
      "source": [
        "# Define fucntion for question_thread Domain-Specific, Heuristic, Linguistic Feature Extraction\n",
        "def q_extract_domain_specific_linguistic_patterns_heuristic_features(sentence, architectural_keywords, fiveW1H_keywords_question, linguistic_patterns):\n",
        "    features = {'contains_architecture_keywords': 0, 'contains_question_words': 0, 'contains_linguistic_patterns': 0}\n",
        "    for keyword in architectural_keywords:\n",
        "        if keyword.lower() in sentence.lower():\n",
        "            features['contains_architecture_keywords'] = 1\n",
        "            break\n",
        "    for keyword in fiveW1H_keywords_question:\n",
        "        if keyword.lower() in sentence.lower():\n",
        "            features['contains_question_words'] = 1\n",
        "            break\n",
        "    for pattern in linguistic_patterns:\n",
        "        if pattern.lower() in sentence.lower():\n",
        "            features['contains_linguistic_patterns'] = 1\n",
        "            break\n",
        "    return features\n",
        "\n",
        "\n",
        "# Define fucntion for answer_thread Domain-Specific, Heuristic, Linguistic Feature Extraction\n",
        "def a_extract_domain_specific_linguistic_patterns_heuristic_features(sentence, architectural_keywords, linguistic_patterns):\n",
        "    features = {'contains_architecture_keywords': 0, 'contains_linguistic_patterns': 0}\n",
        "    for keyword in architectural_keywords:\n",
        "        if keyword.lower() in sentence.lower():\n",
        "            features['contains_architecture_keywords'] = 1\n",
        "            break\n",
        "    for pattern in linguistic_patterns:\n",
        "        if pattern.lower() in sentence.lower():\n",
        "            features['contains_linguistic_patterns'] = 1\n",
        "            break\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGDeXQYkqQXu"
      },
      "outputs": [],
      "source": [
        "# List of architectural keywords categorized for clarity\n",
        "architectural_keywords = {\n",
        "    \"Architectural Patterns and Styles\": [\n",
        "        \"Architecture pattern\", \"Design pattern\", \"MVC\", \"Model View Controller\", \"Monolith\",\n",
        "        \"Microservice\", \"microservices\", \"MVP\", \"Model View Presenter\", \"MVVP\",\n",
        "        \"Model View ViewModel\", \"MVVM\", \"Client-Server\", \"Client Server\", \"Client/Server\",\n",
        "        \"Layered pattern\", \"N-Tier\", \"Event Driven pattern\", \"Event Driven\",\n",
        "        \"Pipe and Filter\", \"Service Oriented Architecture\", \"SOA\", \"Broker\", \"Peer to Peer\",\n",
        "        \"Master-Slave\", \"Master and Slave\", \"Blackboard\", \"Command Query Responsibility Segregation\", \"CQRS\"\n",
        "        \"Hexagonal Architecture\", \"Hexagonal\", \"PublishSubscribe\", \"Publish and Subscribe\", \"Event Sourcing\",\n",
        "        \"Reactive Architecture\", \"Database Per Service\", \"Pipe-and-Filter with Feedback Loops\",\n",
        "        \"Saga Pattern\", \"Service Mesh Architecture\", \"Strangler Fig Pattern\",\n",
        "        \"Multi-Tenant Architecture\", \"Interpreter Architecture\",\n",
        "        \"Pipeline Architecture\", \"Digital Twin Architecture\", \"User Interface\"\n",
        "        \"Monolithic\", \"Event-Driven\", \"Hybrid Architecture\", \"Clean Architecture\"\n",
        "    ],\n",
        "\n",
        "    \"Architectural Tactics\": [\n",
        "        \"Architecture tactic\", \"Design tactic\", \"Heartbeat\", \"Checkpoint\", \"Checkpointing\",\n",
        "        \"Retry Mechanism\", \"Failover Mechanism\", \"Load Balancing\", \"Caching\", \"Concurrency\",\n",
        "        \"Queue-Based Load Management\", \"Data Compression\", \"Lazy Loading\", \"Authentication\",\n",
        "        \"Authorization\", \"Data Encryption\", \"Intrusion Detection\", \"Audit Logging\",\n",
        "        \"Firewalls\", \"API Gateways\", \"Cache\", \"Caching\",\"Loose coupling\",\"Resource Pooling\",\n",
        "        \"Failover\"\n",
        "    ],\n",
        "\n",
        "    \"Software Design Principles\": [\n",
        "        \"Encapsulation\", \"Separation of Concerns\", \"Abstraction\",\n",
        "        \"Component-Based Design\", \"Refactoring\", \"Plug-in Architecture\"\n",
        "    ],\n",
        "\n",
        "    \"Scalability and Performance Optimization\": [\n",
        "        \"Horizontal Scaling\", \"Scale-Out\", \"Vertical Scaling\", \"Scale-Up\",\n",
        "        \"Sharding\", \"Database Replication\", \"Progressive Disclosure\",\"Server Replication\",\n",
        "        \"Undo Mechanism\", \"Redo Mechanism\", \"Event-Bus Pattern\"\n",
        "    ],\n",
        "\n",
        "    \"Reliability and Fault Tolerance\": [\n",
        "        \"Consistent UI Design\", \"Removal from service\", \"Exception Prevention\",\n",
        "        \"Introduce Concurrency\", \"Maintain Multiple Copies of Data\", \"Bound Queue Sizes\",\n",
        "        \"Schedule Resources\", \"Manage Resources\", \"Manage Sampling Rate\", \"Limit Event Response\",\n",
        "        \"Prioritize Events\", \"Bound Execution Times\", \"Increase Resource Efficiency\"\n",
        "    ],\n",
        "\n",
        "    \"Networking and Communication\": [\n",
        "        \"REST\", \"SOAP\", \"WCF\", \"Ping/Echo\", \"Ping and Echo\",\"Shadow\", \"Active Redundancy\", \"Monitor\",\n",
        "        \"Timestamp\", \"Sanity Checking\", \"Voting\", \"Condition Monitoring\"\n",
        "    ],\n",
        "\n",
        "    \"Error Handling and Recovery\": [\n",
        "        \"Degradation\", \"Retry\", \"Ignore Faulty Behavior\", \"Rollback\",\n",
        "        \"Exception Handler\", \"Spare\", \"Non-Stop Forwarding\", \"State Resynchronization\"\n",
        "    ],\n",
        "\n",
        "    \"Security Strategies\": [\n",
        "        \"Increase Resources\", \"Maintain Multiple Copies of Computations\",\n",
        "        \"Detect Intrusion\", \"Detect Service Denial\", \"Verify Message Integrity\",\n",
        "        \"Detect Message Delay\", \"Identify Actors\", \"Limit Access\",\n",
        "        \"Limit Exposure\", \"Encrypt Data\"\n",
        "    ],\n",
        "\n",
        "\n",
        "    \"Modularity and Maintainability\": [\n",
        "        \"Tailor Interface\", \"Reduce Size of a Module\", \"Split Module\",\n",
        "        \"Increase Cohesion\", \"Increase Semantic Coherence\", \"Reduce Coupling\",\n",
        "        \"Encapsulate\", \"Use an Intermediary\", \"Restrict Dependency\", \"Refactor\",\n",
        "        \"Abstract Common Services\", \"Reduce Overhead\", \"Limit Nondeterminism\",\n",
        "        \"Limit Structural Complexity\", \"Limit Complexity\"\n",
        "    ],\n",
        "\n",
        "    \"User Experience and Usability\": [\n",
        "        \"Specialized Interface\", \"Record/Playback\", \"Localize State Storage\",\n",
        "        \"Abstract Data Sources\", \"Sandbox\", \"Executable Assertions\",\n",
        "        \"Support User Initiative\", \"Support System Initiative\",\n",
        "        \"Maintain Task Model\", \"Maintain User Model\", \"Aggregate\", \"Maintain System\"\n",
        "    ],\n",
        "\n",
        "    \"Architecture Design Decision\": [\n",
        "        \"Architecture decision\", \"Trade-offs\", \"Requirements\", \"MongoDB\", \"Redis\"\n",
        "        , \"Redis\" , \"MySQL\" , \"PostgreSQL\" , \"SQL Server\", \"Amazon DynamoDB\", \"TimescaleDB\", \"InfluxDB\"\n",
        "    ],\n",
        "\n",
        "    \"Design Context\": [\n",
        "        \"Embedded System\", \"Mobile Application\", \"Web Application\",\n",
        "        \"Information System\", \"Game application\", \"E-commerce\", \"Distributed System\",\n",
        "        \"Banking System\", \"Android\", \"iOS\", \"Window\",\n",
        "    ],\n",
        "\n",
        "    \"Maintainability\": [\n",
        "        \"Maintainability\", \"Update\", \"Modify\", \"Modular\", \"Decentralized\",\n",
        "        \"Encapsulation\", \"Dependency\", \"Readability\", \"Interdependent\",\n",
        "        \"Understandability\", \"Modifiability\", \"Modularity\", \"Maintain\",\n",
        "        \"Analyzability\", \"Changeability\", \"Testability\"\n",
        "    ],\n",
        "\n",
        "    \"Performance (Efficiency)\": [\n",
        "        \"Performance\", \"Processing time\", \"Response time\", \"Resource Consumption\",\n",
        "        \"Throughput\", \"Efficiency\", \"Operation\", \"Achievement\", \"Interaction\",\n",
        "        \"Accomplishment\", \"Parallelism\"\n",
        "    ],\n",
        "\n",
        "    \"Compatibility\": [\n",
        "        \"Compatibility\", \"Co-existence\", \"Interoperability\", \"Exchange\", \"Sharing\"\n",
        "    ],\n",
        "\n",
        "    \"Usability\": [\n",
        "        \"Usability\", \"Flexibility\", \"Interface\", \"User-friendly\",\n",
        "        \"Configurable\", \"Serviceability\", \"Accessibility\", \"Customizable\"\n",
        "    ]\n",
        "}\n",
        "# this list can be extanded during the future research"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Heuristic features\n",
        "fiveW1H_keywords_question = [\"What\", \"When\", \"Who\", \"Which\", \"How\", \"?\"]\n",
        "\n",
        "\n",
        "#Linguistic Pattern features\n",
        "linguistic_patterns = [\"I want to design\", \"How to architecture\", \"I want to design\", \"I'm designing\",\n",
        "                       \"I'm building\",\"The user should\", \"I need help\",\"I am developing\",\"Advise on\",\"I recommend\",\"I cannot recommend\",\n",
        "                       \"design an application\",\"the best practice\", \"I'm trying to\", \"I'm having a hard\", \"help\", \"you should\",\"I am using\", \"you don't have to do\",\"In order to \",\"it is critical\",\n",
        "                       \"You should\",\"It is recommended\",\"a good approach is\"\n",
        "                       ]"
      ],
      "metadata": {
        "id": "H9VOaVqH-4JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxQ4aXAT2L4E"
      },
      "source": [
        "# III. Similarity and Relevancy Assessment Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for identifying relevant and important issue sentences within a question body"
      ],
      "metadata": {
        "id": "3aL5pEQ1BKrb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qf47FgT5_xz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def question_score_sentences_with_combined_features(question_sentences, question_embeddings,\n",
        "                                                    textcnn_features, weight_bert=0.4, weight_textcnn=0.2, weight_heuristic=0.1,\n",
        "                                                    architectural_keywords=[], fiveW1H_keywords_question=[], linguistic_patterns=[]):\n",
        "\n",
        "    q_sentence_scores = []\n",
        "\n",
        "    full_question_embedding = np.mean(question_embeddings, axis=0)\n",
        "\n",
        "    for i, (q_sentence, tcnn_features) in enumerate(zip(question_sentences, textcnn_features)):\n",
        "\n",
        "        # BERT-based Score using cosine similarity\n",
        "        if i < len(question_embeddings):\n",
        "            bert_score = cosine_similarity(\n",
        "                [question_embeddings[i]], [full_question_embedding])[0][0]\n",
        "        else:\n",
        "            bert_score = 0\n",
        "\n",
        "        # TextCNN score\n",
        "        textcnn_score = weight_textcnn * np.mean(tcnn_features) if isinstance(tcnn_features, np.ndarray) and tcnn_features.size > 0 else 0\n",
        "\n",
        "        # Heuristic Score (e.g., sentence length)\n",
        "        sentence_length = len(q_sentence.split())\n",
        "        max_length = max(len(s.split()) for s in question_sentences)\n",
        "        heuristic_score = sentence_length / max_length if max_length > 0 else 0\n",
        "\n",
        "\n",
        "        # Extract domain-specific, heuristic, linguistic features\n",
        "        q_features = q_extract_domain_specific_linguistic_patterns_heuristic_features(\n",
        "            q_sentence, architectural_keywords, fiveW1H_keywords_question, linguistic_patterns)\n",
        "\n",
        "\n",
        "        # Combine all features\n",
        "        q_combined_score = (weight_heuristic * heuristic_score) + \\\n",
        "                           (weight_bert * bert_score) + \\\n",
        "                           (weight_textcnn * textcnn_score) + \\\n",
        "                           (q_features['contains_architecture_keywords'] * 0.1) + \\\n",
        "                           (q_features['contains_question_words'] * 0.1) + \\\n",
        "                           (q_features['contains_linguistic_patterns'] * 0.1)\n",
        "\n",
        "        q_sentence_scores.append(q_combined_score)\n",
        "\n",
        "    return q_sentence_scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['question_scores'] = dataset.apply(lambda x: question_score_sentences_with_combined_features(\n",
        "    x['processed_question'][0],\n",
        "    x['question_embeddings'],\n",
        "    extract_textcnn_features(x['processed_question'][0], textcnn_model, tokenizer, device),\n",
        "    architectural_keywords=architectural_keywords,\n",
        "    fiveW1H_keywords_question=fiveW1H_keywords_question,\n",
        "    linguistic_patterns=linguistic_patterns\n",
        "), axis=1)"
      ],
      "metadata": {
        "id": "opzWuYZzjfj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ve4uRAo134V"
      },
      "source": [
        "## Function for identifying relevant and important solution sentences within a answer body"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_score_sentences_with_combined_features(question_sentences, answer_sentences, question_embeddings, answer_embeddings,\n",
        "                                                  textcnn_features, weight_bert=0.5, weight_textcnn=0.2, weight_heuristic=0.1,\n",
        "                                                  architectural_keywords=[], fiveW1H_keywords_question=[], linguistic_patterns=[]):\n",
        "    a_sentence_scores = []\n",
        "\n",
        "    for a_sentence, a_embedding, tcnn_features in zip(answer_sentences, answer_embeddings, textcnn_features):\n",
        "        a_embedding = a_embedding.reshape(1, -1)\n",
        "        similarities = [cosine_similarity(a_embedding, q_embedding.reshape(1, -1))[0][0] for q_embedding in question_embeddings]\n",
        "        q_a_bert_score = np.mean(similarities)\n",
        "\n",
        "        if isinstance(tcnn_features, np.ndarray) and tcnn_features.size > 0:\n",
        "            textcnn_score = weight_textcnn * np.mean(tcnn_features)\n",
        "        else:\n",
        "            textcnn_score = 0\n",
        "\n",
        "        # Heuristic Score (e.g., sentence length)\n",
        "        a_sentence_length = len(a_sentence.split())\n",
        "        a_heuristic_score = a_sentence_length / max(len(s.split()) for s in question_sentences)\n",
        "\n",
        "        # Extract domain-specific, heuristic, Linguistic feature Extraction\n",
        "        a_donain_linguistic_patterns_heuristic_features = q_extract_domain_specific_linguistic_patterns_heuristic_features(\n",
        "            a_sentence, architectural_keywords, fiveW1H_keywords_question, linguistic_patterns)\n",
        "\n",
        "        # Combine features with respective weights\n",
        "        a_combined_score = (weight_bert * q_a_bert_score) + (weight_heuristic * a_heuristic_score) + \\\n",
        "                           (weight_textcnn * textcnn_score) + \\\n",
        "                           (a_donain_linguistic_patterns_heuristic_features['contains_architecture_keywords'] * 0.1) + \\\n",
        "                           (a_donain_linguistic_patterns_heuristic_features['contains_linguistic_patterns'] * 0.1)\n",
        "\n",
        "        a_sentence_scores.append(a_combined_score)\n",
        "\n",
        "    return a_sentence_scores"
      ],
      "metadata": {
        "id": "jjUZX8NsYdmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['answer_scores'] = dataset.apply(lambda x: answer_score_sentences_with_combined_features(\n",
        "    x['processed_question'][0],\n",
        "    x['processed_answer'][0],\n",
        "    x['question_embeddings'],\n",
        "    x['answer_embeddings'],\n",
        "\n",
        "    extract_textcnn_features(x['processed_answer'][0], textcnn_model, tokenizer, device),\n",
        "    architectural_keywords=architectural_keywords,\n",
        "    linguistic_patterns=linguistic_patterns),\n",
        "axis=1)"
      ],
      "metadata": {
        "id": "t_Gb6x34YRft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T93MzysU2QOO"
      },
      "source": [
        "# V. Output Layer: Sentence Importance Ranking and Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMaK1egEHtjJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#  Extracts the top-k most important sentences based on model scores mwhile preserving their original order in the text.\n",
        "def issue_solution_extraction(original_sentences, scores, num_sentences=6):\n",
        "\n",
        "    num_sentences = min(num_sentences, len(original_sentences))\n",
        "\n",
        "    # Step 1: Get indices of top-k sentences by descending score\n",
        "    ranked_sentence_indices = np.argsort(scores)[::-1][:num_sentences]\n",
        "\n",
        "    # Step 2: Sort those indices by their original order\n",
        "    ordered_indices = sorted(ranked_sentence_indices)\n",
        "\n",
        "    # Step 3: Extract and concatenate sentences in natural order\n",
        "    issue_solution = [original_sentences[idx] for idx in ordered_indices]\n",
        "    return \" \".join(issue_solution)\n",
        "\n",
        "# Apply the extraction function to both question and answer parts\n",
        "dataset['Issue_Extracted'] = dataset.apply(\n",
        "    lambda x: issue_solution_extraction(\n",
        "        x['processed_question'][0],\n",
        "        x['question_scores']\n",
        "    ),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "dataset['Solution_Extracted'] = dataset.apply(\n",
        "    lambda x: issue_solution_extraction(\n",
        "        x['processed_answer'][0],\n",
        "        x['answer_scores']\n",
        "    ),\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCymFx-6Gc_f",
        "outputId": "7aec225a-96ae-4418-a763-be6e174ae484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Save the dataset with the extracted issues and solutions\n",
        "try:\n",
        "    dataset.to_excel('/content/fileName.xlsx', index=False, engine='openpyxl')\n",
        "    print(\"File saved successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "id": "bdaD4cWhZOoY",
        "outputId": "6823c1a9-8658-426f-cfd7-bf97fd31edcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      Question_title  \\\n",
              "0  Separation of Students and Users in NestJS Mic...   \n",
              "1                         Flutter Clean Architecture   \n",
              "2  Correct .NET Architecture for long running asy...   \n",
              "3  Architecture for white-label mobile apps with ...   \n",
              "4  Implementing Data Source Selection Logic in Cl...   \n",
              "\n",
              "                                     Issue_Extracted  \\\n",
              "0  I need help with the architecture pattern I sh...   \n",
              "1  which part of file structure we should do proc...   \n",
              "2  I am building c# .NET 4.8.1 MVC web applicatio...   \n",
              "3  We have a mobile application that we scale as ...   \n",
              "4  I'm trying to properly design an application a...   \n",
              "\n",
              "                                  Solution_Extracted  \n",
              "0  If you define relations for user (1, M address...  \n",
              "1  For the purpose of clean architecture, the fro...  \n",
              "2  There is no easy and reliable way to do this w...  \n",
              "3  Think of how Tailwind or Nativewind works, tak...  \n",
              "4  Determining the source of the information is b...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba584010-9f05-4a61-b0a4-292d972c822b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question_title</th>\n",
              "      <th>Issue_Extracted</th>\n",
              "      <th>Solution_Extracted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Separation of Students and Users in NestJS Mic...</td>\n",
              "      <td>I need help with the architecture pattern I sh...</td>\n",
              "      <td>If you define relations for user (1, M address...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Flutter Clean Architecture</td>\n",
              "      <td>which part of file structure we should do proc...</td>\n",
              "      <td>For the purpose of clean architecture, the fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Correct .NET Architecture for long running asy...</td>\n",
              "      <td>I am building c# .NET 4.8.1 MVC web applicatio...</td>\n",
              "      <td>There is no easy and reliable way to do this w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Architecture for white-label mobile apps with ...</td>\n",
              "      <td>We have a mobile application that we scale as ...</td>\n",
              "      <td>Think of how Tailwind or Nativewind works, tak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Implementing Data Source Selection Logic in Cl...</td>\n",
              "      <td>I'm trying to properly design an application a...</td>\n",
              "      <td>Determining the source of the information is b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba584010-9f05-4a61-b0a4-292d972c822b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba584010-9f05-4a61-b0a4-292d972c822b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba584010-9f05-4a61-b0a4-292d972c822b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-183d56c3-fa3b-451d-acec-0eda9df57a99\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-183d56c3-fa3b-451d-acec-0eda9df57a99')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-183d56c3-fa3b-451d-acec-0eda9df57a99 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "issue_solutions",
              "summary": "{\n  \"name\": \"issue_solutions\",\n  \"rows\": 369,\n  \"fields\": [\n    {\n      \"column\": \"Question_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 366,\n        \"samples\": [\n          \"Architecture of VS Code\",\n          \"Integrating Spring State Machine in a Hexagonal Architecture\",\n          \"General architecture for React calling AWS and SQS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Issue_Extracted\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 366,\n        \"samples\": [\n          \"Are there articles or presentations about building VS Code - architecture, approach for plug-ins, any abilities to communicate with OS specific stuff etc? First idea is to move stuff to .NET Core, although I am not sure how difficult that is for apps that are using Windows specific resources. All I know is that Electron is used for UI, you can write plug-in for almost any part and it is open-source (or at least Codium is). Therefore, I would like to learn more about architecture, what other languages are used for components and why, what problems were faced etc. But except for some basic info, I end up finding how to create solutions using VS Code. So do you know some good links, perhaps not specifically about VS Code but similar architectural solutions?\",\n          \"1. Business Logic Implementation in Hexagonal Architecture, In a hexagonal architecture, where is the best place to implement the logic for state transitions, especially considering the need for sending/waiting for messages and making REST calls within certain states? State Machine and Service Layer Interaction, How should I structure the interaction between the service layer and state machines in this context? I am looking for best practices that fit within the hexagonal architecture paradigm and ensure maintainability. Configurations for State-Dependent REST Calls,  Could you provide examples or best practices for configuring state machines in Spring Boot where states involve making REST calls? Handling Message Responses, How can I effectively manage the scenarios where the state machine sends a message and needs to wait for a response before moving to the next state? What I've Tried and What I'm Expecting, \\nSo far, I have set up the basic structure of the application following hexagonal architecture principles, separating the core logic from external dependencies.\",\n          \"While waiting for a response, the react app will show status updates, meaning the different stages of the operation taking place on the server. So that's how I'd build it, React calls API gateway, which in turn calls a Lamba function, which then calls SQS and sends a message on some queue, but what I am not sure about is, How would the Lambda wait for the response? Is it a 2-way queue, is Lambda keep polling it until there's an answer and then return it to the client, or would there be two Lambdas? Would there be some sort of Id when sending, and the third party returns a queue message when it's done with that Id that we can match them, or\\\"? What would trigger that 2nd Lamba (if we're doing two lambdas) a message arriving in queue would be the trigger, or would it keep polling, or\\\"? Would it be all about querying some API over HTTP (with Axios or Fetch API or whatever) or would it be some NPM package that queries a queue, in which case I might not even need Lambda checking for a return message, like Amplify from aws-amplify..?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solution_Extracted\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 368,\n        \"samples\": [\n          \"I'm a fan of just passing the id of the data (as a route param or prop). But instead of requesting the data to the API, you could use the store. Check if the data is present (and not outdated) in your store and if no valid data is found in the store, you can request it from your backend database. [external-link].\",\n          \"1, 2,  It is not clear how u use your state machines or why you are using them. But if you are using them as orchestrators, that have access to all different layers (u mentioned business logic, messages + rest calls etc), then this is obviously violating the architecture. If not, then it should be straight-forward in which layer to put it. If you dont do async calls, then the execution wont progress until you get the response. 4,  For state transitions i ve only seen actions to be used. Listeners can be also used for some other actions, like for [external-link].\",\n          \"In order to send a response you need to keep the request that reached lambda \\\"open\\\" (=lambda is running, i.e. polling some results), Which I cannot recommend. If it waits until something is resolved, you will be paying for it as long as it open. (you have to provide docker image, not just code, but then it is basically also serverless, you dont have to care about anything). With container you can also use Websockets, which essentially do what you want (you dont have to do long polling/status polling, you can update client proactively from backend through the websocket). (1 or more lambdas) Process whatever you need, I dont know triggers if 3rd party sends you webhook or you are connected to that 3rd party queue and they let you know something is finished.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Display the extracted issues and solutions\n",
        "issue_solutions = dataset[['Question_title', 'Issue_Extracted', 'Solution_Extracted']]\n",
        "issue_solutions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve1IN8JEQ08j"
      },
      "source": [
        "# Evaluate the extracted issue-solution pairs using Precsion, Recall, and F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkuG-3RfS7DF",
        "outputId": "9bb11ce4-b0c8-4161-b452-97750fc5a3c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Precision, Recall, F1 Scores for \u001b[31mQuestions\u001b[0m:\n",
            "Question_precision    0.883893\n",
            "Question_recall       0.884953\n",
            "Question_f1           0.883493\n",
            "dtype: float64\n",
            "\n",
            "Mean Precision, Recall, F1 Scores for \u001b[31mAnswers\u001b[0m:\n",
            "Answer_precision    0.897541\n",
            "Answer_recall       0.891663\n",
            "Answer_f1           0.893854\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_extracted_Issue_solutions_at_sentence_level(df, ref_col, gen_col):\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    f1_list = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        ref_issue_solution = row[ref_col]\n",
        "        gen_issue_solution = row[gen_col]\n",
        "\n",
        "        if pd.isna(ref_issue_solution) or pd.isna(gen_issue_solution):\n",
        "            continue\n",
        "\n",
        "        ref_sentences = nltk.sent_tokenize(ref_issue_solution)\n",
        "        gen_sentences = nltk.sent_tokenize(gen_issue_solution)\n",
        "\n",
        "        ref_sentences_set = set(ref_sentences)\n",
        "        gen_sentences_set = set(gen_sentences)\n",
        "\n",
        "        precision = len(ref_sentences_set & gen_sentences_set) / len(gen_sentences_set) if gen_sentences_set else 0\n",
        "        recall = len(ref_sentences_set & gen_sentences_set) / len(ref_sentences_set) if ref_sentences_set else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
        "\n",
        "        precision_list.append(precision)\n",
        "        recall_list.append(recall)\n",
        "        f1_list.append(f1)\n",
        "\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'precision': precision_list,\n",
        "        'recall': recall_list,\n",
        "        'f1': f1_list\n",
        "    })\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "# Load the DataFrame\n",
        "df = pd.read_excel('ArchISPE_results.xlsx')\n",
        "\n",
        "question_metrics_df = evaluate_extracted_Issue_solutions_at_sentence_level(df, 'Ground_truth_Issue_Labeled', 'Issue_Extracted')\n",
        "answer_metrics_df = evaluate_extracted_Issue_solutions_at_sentence_level(df, 'Ground_truth_Solution_Labeled', 'Solution_Extracted')\n",
        "\n",
        "# Separate evaluation for question and answer summaries, retaining individual columns for comparison\n",
        "question_metrics_df.columns = [f'Question_{col}' for col in question_metrics_df.columns]\n",
        "answer_metrics_df.columns = [f'Answer_{col}' for col in answer_metrics_df.columns]\n",
        "\n",
        "# Combine question and answer results into a single DataFrame\n",
        "combined_metrics_df = pd.concat([question_metrics_df, answer_metrics_df], axis=1)\n",
        "\n",
        "# Compute Precision, Recall, F1 scores\n",
        "mean_question_metrics = question_metrics_df.mean()\n",
        "mean_answer_metrics = answer_metrics_df.mean()\n",
        "\n",
        "print(\"\\nMean Precision, Recall, F1 Scores for \\033[31mQuestions\\033[0m:\")\n",
        "print(mean_question_metrics)\n",
        "\n",
        "print(\"\\nMean Precision, Recall, F1 Scores for \\033[31mAnswers\\033[0m:\")\n",
        "print(mean_answer_metrics)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}