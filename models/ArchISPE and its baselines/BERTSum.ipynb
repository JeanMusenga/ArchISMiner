{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t01Mf3PsB86m"
   },
   "source": [
    "# Install Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igWjqDttvS6t",
    "outputId": "aa3c4027-7f39-475b-902f-9ee52f7349e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting swifter\n",
      "  Downloading swifter-1.4.0.tar.gz (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from swifter) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.11/dist-packages (from swifter) (5.9.5)\n",
      "Requirement already satisfied: dask>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]>=2.10.0->swifter) (2024.12.1)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from swifter) (4.67.1)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (24.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (0.12.1)\n",
      "Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.6.1)\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]>=2.10.0->swifter) (1.1.21)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->swifter) (2025.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]>=2.10.0->swifter) (18.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.21.0)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Building wheels for collected packages: rouge_score, swifter\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=397819f57646dfefe34f7dc7c2d5c00b58413dbfa4b635756f429d6e9c603a95\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16505 sha256=b879b51dfeea09e10908021c19e666c6017143e2f55bcb2dab4244521a8167ac\n",
      "  Stored in directory: /root/.cache/pip/wheels/ef/7f/bd/9bed48f078f3ee1fa75e0b29b6e0335ce1cb03a38d3443b3a3\n",
      "Successfully built rouge_score swifter\n",
      "Installing collected packages: rouge_score, swifter\n",
      "Successfully installed rouge_score-0.1.2 swifter-1.4.0\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install rouge_score swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p792IFeBwlnT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import re\n",
    "import gc\n",
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from rouge_score import rouge_scorer\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ijXduVlwpUy",
    "outputId": "817314c5-b2e2-4355-8a94-002a49530af8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yp4B3c-VCDfk"
   },
   "source": [
    "# Read the Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aE4A9NwQwpHy"
   },
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "data = pd.read_excel('366_ARPs_for_extracting_Issue_Solution_Pairs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOq3gOIXwwLr"
   },
   "outputs": [],
   "source": [
    "# Applying heuristic technique to reduce noice in the data\n",
    "def clean_dataset(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "    for a in soup.find_all('a'):\n",
    "        a.replace_with('[external-link]')\n",
    "\n",
    "    for img in soup.find_all('img'):\n",
    "        img.replace_with('[figure]')\n",
    "\n",
    "    for code in soup.find_all('code'):\n",
    "        code.replace_with('[code-snippet]')\n",
    "\n",
    "    for table in soup.find_all('table'):\n",
    "        table.replace_with('[table]')\n",
    "\n",
    "    clean_text = soup.get_text()\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# Apply the function to 'Question_body' and 'Answer_body' columns\n",
    "dataset['Question_body_cleaned'] = dataset['Question_body'].apply(clean_dataset)\n",
    "dataset['Answer_body_cleaned'] = dataset['Answer_body'].apply(clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335,
     "referenced_widgets": [
      "96e9c5c873da41f095373ab0675c5700",
      "de5db7e07b6b451986da6810d541a603",
      "d2d99a0bfa0243dd8174bdbb9374007b",
      "2224c2c066b3420ead85367eef2ce82f",
      "7ff42eecf9374db19fdacc53799f08f0",
      "ad651381b1c44e30926ebb6fbcfc6148",
      "475339b88ae44d0da5e0bb10a452ecad",
      "a6c1d3f20e0e43928bc820f6748baaf1",
      "65f988a5315c41ccb307f26962216cbb",
      "fa7fc2f43ece494c8c44f8ea31fce3ac",
      "e6ca102034174bc2b107d7dd2a8dcb4d",
      "d5edb9f1e17e41269bc0970fd05766e4",
      "90d217e417fe4fe4808c36b92ff69850",
      "46b170a02c4a468b90dffeca3ca0a99f",
      "724ed013acb44c59ad478201604a7d1a",
      "74c2fe48af414e9283d66b5b976789a8",
      "1e1062ea7da54740a6ed15f72cbb3442",
      "e9da6d6ad9e64304b287ca7cb4d3ff78",
      "5a96fbe3f3434099954b9b56f66e5cb5",
      "8b80d9598273490c81101f18859398df",
      "ec538598776b40e29a1249970fd7677e",
      "c573a122c2e443fa816908d8d4d95385"
     ]
    },
    "id": "fbxkzCxdw_JF",
    "outputId": "a86cc2c2-d8e3-4870-e9fe-0678bd5be5f8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e9c5c873da41f095373ab0675c5700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5edb9f1e17e41269bc0970fd05766e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data:\n",
      "                          Question_body_preprocessed  \\\n",
      "0  need help architecture pattern use nestjs proj...   \n",
      "1  part file structure process fromjson tojson bu...   \n",
      "2  building c net mvc web application would allow...   \n",
      "3  mobile application scale white label develop r...   \n",
      "4  im trying properly design application accordin...   \n",
      "\n",
      "                            Answer_body_preprocessed  \n",
      "0  first talking strictly cqrs pattern designing ...  \n",
      "1  purpose clean architecture fromjson tojson met...  \n",
      "2  easy reliable way without splitting task multi...  \n",
      "3  simple answer question think tailwind nativewi...  \n",
      "4  determining source information business logic ...  \n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "import swifter\n",
    "data['Question_body_preprocessed'] = data['Question_body_cleaned'].swifter.apply(lambda x: preprocess_text(x) if pd.notnull(x) else \"\")\n",
    "data['Answer_body_preprocessed'] = data['Answer_body_cleaned'].swifter.apply(lambda x: preprocess_text(x) if pd.notnull(x) else \"\")\n",
    "\n",
    "print(\"Preprocessed data:\")\n",
    "print(data[['Question_body_preprocessed', 'Answer_body_preprocessed']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S_Y2b1RFwLg"
   },
   "source": [
    "# Define the BertSum model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkNHfUckAK39"
   },
   "outputs": [],
   "source": [
    "# Define the BertSum model\n",
    "class BertSum:\n",
    "    def __init__(self, model_name='bert-base-uncased', num_sentences=6):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertModel.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "        self.num_sentences = num_sentences\n",
    "\n",
    "    def summarize_and_get_embeddings(self, texts):\n",
    "        summaries = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for text in texts:\n",
    "            if not text:\n",
    "                summaries.append(\"\")\n",
    "                embeddings_list.append(None)\n",
    "                continue\n",
    "\n",
    "            sentences = sent_tokenize(text)\n",
    "            if not sentences:\n",
    "                summaries.append(\"\")\n",
    "                embeddings_list.append(None)\n",
    "                continue\n",
    "\n",
    "            inputs = self.tokenizer(sentences, return_tensors='pt', padding=True, truncation=True)\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "            # Get the sentence embeddings by averaging over token embeddings\n",
    "            sentence_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "            # Score sentences based on norm\n",
    "            scores = torch.norm(sentence_embeddings, dim=1)\n",
    "\n",
    "            # Select the top N sentences (up to 6 or fewer if less than 6 sentences)\n",
    "            num_sentences_to_select = min(self.num_sentences, len(sentences))\n",
    "            top_sentence_idxs = scores.topk(num_sentences_to_select).indices.tolist()\n",
    "\n",
    "            # Sort indices for natural order and join with proper delimiters\n",
    "            sorted_top_sentences = sorted([sentences[idx].strip() for idx in top_sentence_idxs])\n",
    "            summary = '. '.join(sorted_top_sentences)\n",
    "\n",
    "            if summary and not summary.endswith('.'):\n",
    "                summary += '.'\n",
    "\n",
    "            summaries.append(summary)\n",
    "            embeddings_list.append(sentence_embeddings.detach().cpu().numpy())\n",
    "\n",
    "        return summaries, embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415,
     "referenced_widgets": [
      "c9f03540e367408b8e90a9f56cd62d70",
      "950aa29295bd4f589f82177038fe0b6b",
      "71d1ea289dbf4e4f8db3ece8acf392ac",
      "8245c04224094106a295f07fec2b8ef0",
      "775efb2fdb1b409eb1e812823ee41386",
      "954ebc91dd644fc08286ebe59fe8acd2",
      "765e29754cbf4b30875890dfdbdc3737",
      "69ce745394584ea58a521f3a22887a09",
      "85e4af48d06c43a8b57abdb1cdf58999",
      "2dba1450481145509a012494e0d80d14",
      "3329f1f31f624b20b9180861c73007f8",
      "b75e7f0c14d94240911ac4dd6f258ece",
      "476ab1c124fd4c429b9324e339b58b0e",
      "08d858c5a0f745b3bfdae837656aa47d",
      "282493508749449dafdf2570ddd25fd4",
      "4b7739cace5540d5a748600766182f03",
      "99213b049ef743fd8d385bd884e82672",
      "b68429bbcb1b43eb9a342db7e866ae00",
      "cbc861e32ecb400498980c118b6d9a67",
      "647ece6dab0749429bfa7baa98237399",
      "7bd4ba6f3e554febb9e437af9b055e4f",
      "7c3f866e360541ac88cf4c4a9bb4db19",
      "75df0a2adb1f42638b8b932fd59f0b22",
      "dc3ac402130248d79f8a8b3c8105e648",
      "c6be4683211942a78ec98854faf3dee7",
      "ae3441f3249043a3a458c9f1931b9c48",
      "c29589bfaf134d3f8a3656b863b0983f",
      "27c2892ec0bd4620974fb8460096490a",
      "0a9b99d0d2484d939f2b17c62169d597",
      "71f452cbbedc47a1ae9ee6cfd3975c96",
      "6572c409e636462797506c8c30295cf4",
      "8ac9569ade5b44af8b2fb9607ed95437",
      "4cc4b801bfec4d3e880ccd667280a3b3",
      "5c19ec94fafd44eda9da8760ab60e1a9",
      "fc92f3d151c74f71bfc0121a480f7be2",
      "76b4bb5f10e04e08beeb45b787150503",
      "29e7e1d7ba4a4465b3aa3f5ce42dc869",
      "87a5381165a24f619b181928b83e605f",
      "3a592fb5b9ed4a8bb6677f95760ecd23",
      "24ca85bec1e54add895ca150e43b26a2",
      "36b555be698543498d8de969fe1f9bdf",
      "2b3c741ab4aa49b7a72393d6ad336301",
      "0e26cc7fd5ee4fa2881833111f065ab7",
      "89d0fbb03d89469c8f98efdce3cd5006",
      "a5ac18a1d2a74f679e62f179aa06fe5a",
      "db78ba7807f54ff2a3480cea1630a181",
      "c41fae10a5ab407e9be719ba56d26f8f",
      "ff87de15ca6b4078a3dd2f3fd3a21d94",
      "66c8b4e368be48bf9676a91f4d725e28",
      "dec3cd068764475198b8164b66bb387c",
      "096eb81ab1564a8387145d738aafd790",
      "36564ec57dec435487303fe2e207cd9c",
      "265856f3de304ac699811bba733f4d7b",
      "a81c032bb7f14faf8bfb1df686a0169a",
      "8edf967f47504b05a7a618838ff73312"
     ]
    },
    "id": "C2_QDGtTxuww",
    "outputId": "da9979b2-c02b-459b-a0e5-015b836c8a33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f03540e367408b8e90a9f56cd62d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75e7f0c14d94240911ac4dd6f258ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75df0a2adb1f42638b8b932fd59f0b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c19ec94fafd44eda9da8760ab60e1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ac18a1d2a74f679e62f179aa06fe5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Question Body...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 183/183 [08:09<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Answer Body...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 183/183 [09:57<00:00,  3.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "bertsum = BertSum()\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "# Prepare lists for storing summaries/issues or solutions and embeddings\n",
    "question_summaries = []\n",
    "question_embeddings = []\n",
    "answer_summaries = []\n",
    "answer_embeddings = []\n",
    "\n",
    "# Function to process batches and manage memory\n",
    "def process_text_column(text_column):\n",
    "    summaries = []\n",
    "    embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(text_column), batch_size), desc=\"Processing Batches\"):\n",
    "        batch = text_column[i:i + batch_size].tolist()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_summaries, batch_embeddings = bertsum.summarize_and_get_embeddings(batch)\n",
    "\n",
    "        # Convert only PyTorch tensors to CPU before storing\n",
    "        batch_embeddings = [emb.cpu().numpy() if isinstance(emb, torch.Tensor) else emb for emb in batch_embeddings]\n",
    "\n",
    "        summaries.extend(batch_summaries)\n",
    "        embeddings.extend(batch_embeddings)\n",
    "\n",
    "        # Explicitly clear CUDA cache\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return summaries, embeddings\n",
    "\n",
    "# Process Question Body\n",
    "print(\"Processing Question Body...\")\n",
    "question_summaries, question_embeddings = process_text_column(data['Question_body'])\n",
    "\n",
    "# Process Answer Body\n",
    "print(\"Processing Answer Body...\")\n",
    "answer_summaries, answer_embeddings = process_text_column(data['Answer_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Luhu0IRb0Gp_"
   },
   "outputs": [],
   "source": [
    "# Assign results to DataFrame\n",
    "data['Issue_Extracted'] = question_summaries\n",
    "data['Question_embeddings'] = question_embeddings\n",
    "data['Solution_Extracted'] = answer_summaries\n",
    "data['Answer_embeddings'] = answer_embeddings\n",
    "\n",
    "# Save to Excel in chunks\n",
    "output_path = \"BertSum_Extracted_Issue_Solution.xlsx\"\n",
    "data.to_excel(output_path, index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmxvjInbT20Z"
   },
   "source": [
    "# Display the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "BlQV8nDU0xiZ",
    "outputId": "847125b1-a047-4f51-89f4-23deb06d4a43"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"summaries\",\n  \"rows\": 366,\n  \"fields\": [\n    {\n      \"column\": \"Question_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 365,\n        \"samples\": [\n          \"Architecture of VS Code\",\n          \"Integrating Spring State Machine in a Hexagonal Architecture\",\n          \"General architecture for React calling AWS and SQS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Issue_Extracted\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 365,\n        \"samples\": [\n          \"<p>Are there articles or presentations about building VS Code - architecture, approach for plug-ins, any abilities to communicate with OS specific stuff etc?</p>\\n\\n<p>Coming form .NET, we have Windows-only apps but want to go cross-platform.. All I know is that Electron is used for UI, you can write plug-in for almost any part and it is open-source (or at least Codium is).</p>\\n\\n<p>Therefore, I would like to learn more about architecture, what other languages are used for components and why, what problems were faced etc.. But except for some basic info, I end up finding how to create solutions using VS Code.</p>\\n\\n<p>So do you know some good links, perhaps not specifically about VS Code but similar architectural solutions?</p>\\n\\n<p>Thx</p>. First idea is to move stuff to .NET Core, although I am not sure how difficult that is for apps that are using Windows specific resources.. In any case we are also looking into other options, including possibility to write something from scratch.. VS Code came to mind as cross-platform and extendable.\",\n          \"<p>I am developing a Spring Boot application using hexagonal architecture.. Handling Message Responses:</em></p>\\n<p>How can I effectively manage the scenarios where the state machine sends a message and needs to wait for a response before moving to the next state?</p>\\n<p><em>4.. I've also implemented the configuration of the two state machines</p>\\n<p><strong>Expectations:</strong></p>\\n<p>For the messaging logic, I expect the state machine to handle sending a message, pausing its flow, and then resuming or transitioning to a new state upon receiving the corresponding response, akin to a TCP-like communication model.</p>\\n<p>For the decision making in the states REST calls to other components will be needed.</p>. My primary challenge is effectively integrating these state machines within the hexagonal architecture, especially considering the following requirements:</p>\\n<ol>\\n<li>State Machines Sending Messages and Awaiting Responses: The state machines need to send messages and wait for a response before proceeding to the next state.</li>\\n<li>Making REST Calls Within States: In certain states, the state machine needs to perform various REST calls.</li>\\n</ol>\\n<p><strong>Questions:</strong></p>\\n<p><em>1.. State Machine and Service Layer Interaction:</em></p>\\n<p>How should I structure the interaction between the service layer and state machines in this context?. The application uses two Spring State Machines: one for a requesting process and another for a receiving process.\",\n          \"!. Keep polling some API?. Kinda new to AWS.. One that sends a queue and the other triggered by a response\\\"\\u00a6?. So that's how I'd build it: React calls API gateway, which in turn calls a Lamba function, which then calls SQS and sends a message on some queue.. Would it be all about querying some API over HTTP (with Axios or Fetch API or whatever) or would it be some NPM package that queries a queue, in which case I might not even need Lambda checking for a return message, like Amplify from aws-amplify..?.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Solution_Extracted\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 365,\n        \"samples\": [\n          \"<p>VSCode is \\\"simply\\\" an Editor/IDE/Dev platform built upon Electron.. For instance if you want to do the UI in Blazor.. Like usage of Local Storage, Session Storage etc.</p>\\n\\n<p>There are some basic high level architecture described on Electron docs <a href=\\\"https://www.electronjs.org/docs/tutorial/application-architecture\\\" rel=\\\"noreferrer\\\">https://www.electronjs.org/docs/tutorial/application-architecture</a>.</p>\\n\\n<p>A walk through of the internal architecture of Electron: <a href=\\\"https://www.youtube.com/watch?v=oTDjyMTZU1s\\\" rel=\\\"noreferrer\\\">https://www.youtube.com/watch?v=oTDjyMTZU1s</a></p>\\n\\n<p>As you likely already have a ton of C# code and libraries - as well as C# coders - that you may want to reuse there is also a .NET version of Electron <a href=\\\"https://github.com/ElectronNET/Electron.NET\\\" rel=\\\"noreferrer\\\">https://github.com/ElectronNET/Electron.NET</a> .. The major part of your application architecture will be the same as for any browser based application using HTML5.. Typically a render process and a main process run in parallell swapping messages for communication.. You simply bundle the browser and backend.</p>.\",\n          \"<p>1, 2: It is not clear how u use your state machines or why you are using them.. But if you are using them as orchestrators, that have access to all different layers (u mentioned business logic, messages + rest calls etc), then this is obviously violating the architecture.. If not, then it should be straight-forward in which layer to put it.</p>\\n<p>2, 3: I dont see the struggle.. If you dont do async calls, then the execution wont progress until you get the response.. Is there some issue that i dont see?</p>\\n<p>4: For state transitions i ve only seen actions to be used.. Listeners can be also used for some other actions, like for <a href=\\\"https://docs.spring.io/spring-statemachine/docs/1.0.2.RELEASE/reference/html/sm-error-handling.html\\\" rel=\\\"nofollow noreferrer\\\">listening to errors</a></p>.\",\n          \"If you want to have it like this (=client send request, it will be open for i.e.. In order to send a response you need to keep the request that reached lambda &quot;open&quot; (=lambda is running, i.e.. Lambda is charged per miliseconds running.. Single container can usually handle hundreds of concurrent requests.. Status of the flow (=this will be called periodically by React client after creating the flow)\\n</ol>. polling some results).\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "summaries"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-6ec01c3e-eee8-47c1-9a4b-2502ab0624a7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_title</th>\n",
       "      <th>Issue_Extracted</th>\n",
       "      <th>Solution_Extracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Separation of Students and Users in NestJS Mic...</td>\n",
       "      <td>Considering this, creating users, contacts, an...</td>\n",
       "      <td>But still, if you inject repository for &lt;em&gt;on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flutter Clean Architecture</td>\n",
       "      <td>I created entity class on business layer and a...</td>\n",
       "      <td>Business Layer (Domain Layer):\\n\\nThe business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Correct .NET Architecture for long running asy...</td>\n",
       "      <td>How do I handle re-attaching the UI web page t...</td>\n",
       "      <td>&lt;a href=\"https://i.sstatic.net/XZbMs.png\" rel=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecture for white-label mobile apps with ...</td>\n",
       "      <td>Advise on what approach to development and sca...</td>\n",
       "      <td>&lt;strong&gt;Use dependency injection&lt;/strong&gt; -&amp;gt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Implementing Data Source Selection Logic in Cl...</td>\n",
       "      <td>&lt;strong&gt;Approach 2&lt;/strong&gt;\\nUserRepository in...</td>\n",
       "      <td>By moving the selection logic to the UseCase, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ec01c3e-eee8-47c1-9a4b-2502ab0624a7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6ec01c3e-eee8-47c1-9a4b-2502ab0624a7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6ec01c3e-eee8-47c1-9a4b-2502ab0624a7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-93af38ca-f026-401a-88f0-97c7cc6787fe\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93af38ca-f026-401a-88f0-97c7cc6787fe')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-93af38ca-f026-401a-88f0-97c7cc6787fe button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                      Question_title  \\\n",
       "0  Separation of Students and Users in NestJS Mic...   \n",
       "1                         Flutter Clean Architecture   \n",
       "2  Correct .NET Architecture for long running asy...   \n",
       "3  Architecture for white-label mobile apps with ...   \n",
       "4  Implementing Data Source Selection Logic in Cl...   \n",
       "\n",
       "                                     Issue_Extracted  \\\n",
       "0  Considering this, creating users, contacts, an...   \n",
       "1  I created entity class on business layer and a...   \n",
       "2  How do I handle re-attaching the UI web page t...   \n",
       "3  Advise on what approach to development and sca...   \n",
       "4  <strong>Approach 2</strong>\\nUserRepository in...   \n",
       "\n",
       "                                  Solution_Extracted  \n",
       "0  But still, if you inject repository for <em>on...  \n",
       "1  Business Layer (Domain Layer):\\n\\nThe business...  \n",
       "2  <a href=\"https://i.sstatic.net/XZbMs.png\" rel=...  \n",
       "3  <strong>Use dependency injection</strong> -&gt...  \n",
       "4  By moving the selection logic to the UseCase, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the summaries/issue–solution pairs for both questions and answers\n",
    "summaries = data[['Question_title', 'Issue_Extracted', 'Solution_Extracted']]\n",
    "summaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEWdchJIhA52"
   },
   "source": [
    "# Evaluation of issue-solution pairs extracted by BertSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjC0fRICmRFv",
    "outputId": "7fa08e11-b2b2-4a4a-ca4b-968f223f97fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Precision, Recall, F1 Scores for \u001b[31mQuestions\u001b[0m:\n",
      "Question_precision    0.039936\n",
      "Question_recall       0.026438\n",
      "Question_f1           0.031186\n",
      "dtype: float64\n",
      "\n",
      "Mean Precision, Recall, F1 Scores for \u001b[31mAnswers\u001b[0m:\n",
      "Answer_precision    0.036976\n",
      "Answer_recall       0.026708\n",
      "Answer_f1           0.030522\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_summaries_at_sentence_level(df, ref_col, gen_col):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        ref_summary = row[ref_col]\n",
    "        gen_summary = row[gen_col]\n",
    "\n",
    "        if pd.isna(ref_summary) or pd.isna(gen_summary):\n",
    "            continue\n",
    "\n",
    "        # List of sentences in the ground-truth benchmark\n",
    "        ref_sentences = nltk.sent_tokenize(ref_summary)\n",
    "\n",
    "        # List of sentences in the generated issue and solution pairs\n",
    "        gen_sentences = nltk.sent_tokenize(gen_summary)\n",
    "\n",
    "        # Precision, Recall, F1 (binary classification based on exact match)\n",
    "        ref_sentences_set = set(ref_sentences)\n",
    "        gen_sentences_set = set(gen_sentences)\n",
    "\n",
    "        precision = len(ref_sentences_set & gen_sentences_set) / len(gen_sentences_set) if gen_sentences_set else 0\n",
    "        recall = len(ref_sentences_set & gen_sentences_set) / len(ref_sentences_set) if ref_sentences_set else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'precision': precision_list,\n",
    "        'recall': recall_list,\n",
    "        'f1': f1_list\n",
    "    })\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_excel('BertSum_Extracted_Issue_Solution.xlsx')\n",
    "\n",
    "question_metrics_df = evaluate_summaries_at_sentence_level(df, 'Ground_truth_Issue_Labeled', 'Issue_Extracted')\n",
    "answer_metrics_df = evaluate_summaries_at_sentence_level(df, 'Ground_truth_Solution_Labeled', 'Solution_Extracted')\n",
    "\n",
    "question_metrics_df.columns = [f'Question_{col}' for col in question_metrics_df.columns]\n",
    "answer_metrics_df.columns = [f'Answer_{col}' for col in answer_metrics_df.columns]\n",
    "\n",
    "combined_metrics_df = pd.concat([question_metrics_df, answer_metrics_df], axis=1)\n",
    "\n",
    "# Compute overall Precision, Recall, F1 scores\n",
    "mean_question_metrics = question_metrics_df.mean()\n",
    "mean_answer_metrics = answer_metrics_df.mean()\n",
    "\n",
    "print(\"\\nMean Precision, Recall, F1 Scores for \\033[31mQuestions\\033[0m:\")\n",
    "print(mean_question_metrics)\n",
    "\n",
    "print(\"\\nMean Precision, Recall, F1 Scores for \\033[31mAnswers\\033[0m:\")\n",
    "print(mean_answer_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
